2024-11-21 00:51:14,361 - INFO - Checkpoint directory: ./results/unbiased/online/32
2024-11-21 00:51:14,361 - INFO - Configuration:
2024-11-21 00:51:14,362 - INFO - sim_coeff: 25.0
2024-11-21 00:51:14,362 - INFO - std_coeff: 25
2024-11-21 00:51:14,362 - INFO - cov_coeff: 1
2024-11-21 00:51:14,362 - INFO - batch_sizes: [256, 128, 64, 32, 16, 8]
2024-11-21 00:51:14,362 - INFO - num_epochs: 50
2024-11-21 00:51:14,362 - INFO - max_lr_vicreg: 0.37500000000000006
2024-11-21 00:51:14,362 - INFO - momentum: 0.9
2024-11-21 00:51:14,362 - INFO - weight_decay: 0.0001
2024-11-21 00:51:14,362 - INFO - final_lr_schedule_value: 5e-05
2024-11-21 00:51:14,362 - INFO - warmup_epochs: 5
2024-11-21 00:51:14,362 - INFO - batch_size_evaluate: 32
2024-11-21 00:51:14,362 - INFO - num_eval_epochs: 50
2024-11-21 00:51:14,362 - INFO - max_lr_linear: 0.078125
2024-11-21 00:51:14,362 - INFO - linear_momentum: 0.9
2024-11-21 00:51:14,363 - INFO - linear_weight_decay: 0.0
2024-11-21 00:51:14,363 - INFO - backbone: resnet18
2024-11-21 00:51:14,363 - INFO - augs_train_type: lightly
2024-11-21 00:51:14,363 - INFO - augs_eval_enable: False
2024-11-21 00:51:14,363 - INFO - num_layers: 3
2024-11-21 00:51:14,363 - INFO - projection_head_dims: [512, 2048]
2024-11-21 00:51:14,363 - INFO - probe: online
2024-11-21 00:51:14,363 - INFO - loss: unbiased
2024-11-21 00:51:14,363 - INFO - batch_size_sharing: True
2024-11-21 00:51:14,363 - INFO - scale_lr_batched: True
2024-11-21 00:51:14,363 - INFO - batch_size: 32
2024-11-21 00:51:14,363 - INFO - checkpoint_dir: ./results/unbiased/online/32
2024-11-21 00:51:14,363 - INFO - Running with batch_size=32
2024-11-21 00:51:14,363 - INFO - Using device: cuda
2024-11-21 00:51:14,364 - INFO - Setting up experiment...
2024-11-21 00:51:14,364 - INFO - Using ResNet18 backbone
2024-11-21 00:51:14,639 - INFO - Using unbiased VICReg loss
2024-11-21 00:51:14,639 - INFO - Setting up datasets and dataloaders
2024-11-21 00:51:15,860 - INFO - Created dataloaders with batch size 32 and evaluate 32
2024-11-21 00:51:15,862 - INFO - Created optimizers with learning rates: vicreg=0.37500000000000006, linear=0.078125
2024-11-21 00:51:15,862 - INFO - Loaded checkpoints: vicreg_epoch=0, linear_epoch=0
2024-11-21 00:51:15,862 - INFO - Starting from epoch vicreg_start:0
2024-11-21 00:51:15,862 - INFO - Writing visualization data to TensorBoard
2024-11-21 00:51:17,052 - INFO - Successfully wrote visualization data to TensorBoard
2024-11-21 00:51:17,087 - INFO - Beginning train + evaluate for online probing
2024-11-21 00:51:17,087 - INFO - Continuing training from epoch 0 to 50
2024-11-21 00:52:51,996 - INFO - Epoch: 00, unbiasedVICReg loss: 115.70794, Train Loss: 2.75434, Train Acc: 25.83%
2024-11-21 00:52:51,996 - INFO - Epoch: 00, Invariance loss: 0.01428
2024-11-21 00:52:51,996 - INFO - Epoch: 00, Variance loss: 0.92104
2024-11-21 00:52:51,996 - INFO - Epoch: 00, Covariance loss: 0.09476
2024-11-21 00:52:51,996 - INFO - Epoch: 00, Compare losses: 23.47765 == 115.70794
2024-11-21 00:52:52,174 - INFO - Epoch: 00, Optimizer LR: 0.05086161, Linear Optimizer LR: 0.00078125
2024-11-21 00:52:56,241 - INFO - Epoch: 00, Test Loss: 2.34885, Test Acc: 15.70%
2024-11-21 00:54:34,429 - INFO - Epoch: 01, unbiasedVICReg loss: 45.05230, Train Loss: 1.70405, Train Acc: 38.66%
2024-11-21 00:54:34,429 - INFO - Epoch: 01, Invariance loss: 0.00366
2024-11-21 00:54:34,429 - INFO - Epoch: 01, Variance loss: 0.92735
2024-11-21 00:54:34,429 - INFO - Epoch: 01, Covariance loss: 0.00443
2024-11-21 00:54:34,429 - INFO - Epoch: 01, Compare losses: 23.27952 == 45.05230
2024-11-21 00:54:35,265 - INFO - Epoch: 01, Optimizer LR: 0.19929665, Linear Optimizer LR: 0.00078125
2024-11-21 00:54:39,498 - INFO - Epoch: 01, Test Loss: 2.02539, Test Acc: 24.99%
2024-11-21 00:56:14,241 - INFO - Epoch: 02, unbiasedVICReg loss: 45.02526, Train Loss: 1.63755, Train Acc: 41.74%
2024-11-21 00:56:14,241 - INFO - Epoch: 02, Invariance loss: 0.00298
2024-11-21 00:56:14,241 - INFO - Epoch: 02, Variance loss: 0.92535
2024-11-21 00:56:14,241 - INFO - Epoch: 02, Covariance loss: 0.00479
2024-11-21 00:56:14,241 - INFO - Epoch: 02, Compare losses: 23.21301 == 45.02526
2024-11-21 00:56:15,071 - INFO - Epoch: 02, Optimizer LR: 0.30702606, Linear Optimizer LR: 0.00078125
2024-11-21 00:56:19,270 - INFO - Epoch: 02, Test Loss: 1.88139, Test Acc: 29.96%
2024-11-21 00:57:57,498 - INFO - Epoch: 03, unbiasedVICReg loss: 45.01273, Train Loss: 1.57505, Train Acc: 44.45%
2024-11-21 00:57:57,498 - INFO - Epoch: 03, Invariance loss: 0.00265
2024-11-21 00:57:57,498 - INFO - Epoch: 03, Variance loss: 0.92421
2024-11-21 00:57:57,498 - INFO - Epoch: 03, Covariance loss: 0.00503
2024-11-21 00:57:57,498 - INFO - Epoch: 03, Compare losses: 23.17671 == 45.01273
2024-11-21 00:57:58,321 - INFO - Epoch: 03, Optimizer LR: 0.00152830, Linear Optimizer LR: 0.00078125
2024-11-21 00:58:02,482 - INFO - Epoch: 03, Test Loss: 1.77430, Test Acc: 34.22%
2024-11-21 00:59:37,320 - INFO - Epoch: 04, unbiasedVICReg loss: 45.00453, Train Loss: 1.52518, Train Acc: 46.19%
2024-11-21 00:59:37,320 - INFO - Epoch: 04, Invariance loss: 0.00244
2024-11-21 00:59:37,320 - INFO - Epoch: 04, Variance loss: 0.92346
2024-11-21 00:59:37,320 - INFO - Epoch: 04, Covariance loss: 0.00520
2024-11-21 00:59:37,320 - INFO - Epoch: 04, Compare losses: 23.15260 == 45.00453
2024-11-21 00:59:38,170 - INFO - Epoch: 04, Optimizer LR: 0.33919546, Linear Optimizer LR: 0.00078125
2024-11-21 00:59:42,455 - INFO - Epoch: 04, Test Loss: 1.71045, Test Acc: 37.36%
2024-11-21 01:01:20,238 - INFO - Epoch: 05, unbiasedVICReg loss: 44.99805, Train Loss: 1.49108, Train Acc: 47.69%
2024-11-21 01:01:20,238 - INFO - Epoch: 05, Invariance loss: 0.00228
2024-11-21 01:01:20,238 - INFO - Epoch: 05, Variance loss: 0.92284
2024-11-21 01:01:20,238 - INFO - Epoch: 05, Covariance loss: 0.00533
2024-11-21 01:01:20,239 - INFO - Epoch: 05, Compare losses: 23.13338 == 44.99805
2024-11-21 01:01:21,098 - INFO - Epoch: 05, Optimizer LR: 0.15239569, Linear Optimizer LR: 0.00078125
2024-11-21 01:01:25,128 - INFO - Epoch: 05, Test Loss: 1.60137, Test Acc: 43.47%
2024-11-21 01:03:00,004 - INFO - Epoch: 06, unbiasedVICReg loss: 44.99310, Train Loss: 1.44808, Train Acc: 49.49%
2024-11-21 01:03:00,005 - INFO - Epoch: 06, Invariance loss: 0.00215
2024-11-21 01:03:00,005 - INFO - Epoch: 06, Variance loss: 0.92241
2024-11-21 01:03:00,005 - INFO - Epoch: 06, Covariance loss: 0.00542
2024-11-21 01:03:00,005 - INFO - Epoch: 06, Compare losses: 23.11939 == 44.99310
2024-11-21 01:03:00,816 - INFO - Epoch: 06, Optimizer LR: 0.08707087, Linear Optimizer LR: 0.00078125
2024-11-21 01:03:04,906 - INFO - Epoch: 06, Test Loss: 1.55461, Test Acc: 45.23%
2024-11-21 01:04:42,926 - INFO - Epoch: 07, unbiasedVICReg loss: 44.98843, Train Loss: 1.40989, Train Acc: 51.07%
2024-11-21 01:04:42,927 - INFO - Epoch: 07, Invariance loss: 0.00204
2024-11-21 01:04:42,927 - INFO - Epoch: 07, Variance loss: 0.92197
2024-11-21 01:04:42,927 - INFO - Epoch: 07, Covariance loss: 0.00551
2024-11-21 01:04:42,927 - INFO - Epoch: 07, Compare losses: 23.10580 == 44.98843
2024-11-21 01:04:43,790 - INFO - Epoch: 07, Optimizer LR: 0.36911013, Linear Optimizer LR: 0.00078125
2024-11-21 01:04:47,853 - INFO - Epoch: 07, Test Loss: 1.47347, Test Acc: 48.53%
2024-11-21 01:06:22,772 - INFO - Epoch: 08, unbiasedVICReg loss: 44.98468, Train Loss: 1.37676, Train Acc: 52.42%
2024-11-21 01:06:22,773 - INFO - Epoch: 08, Invariance loss: 0.00195
2024-11-21 01:06:22,773 - INFO - Epoch: 08, Variance loss: 0.92165
2024-11-21 01:06:22,773 - INFO - Epoch: 08, Covariance loss: 0.00558
2024-11-21 01:06:22,773 - INFO - Epoch: 08, Compare losses: 23.09557 == 44.98468
2024-11-21 01:06:23,622 - INFO - Epoch: 08, Optimizer LR: 0.02323941, Linear Optimizer LR: 0.00078125
2024-11-21 01:06:27,674 - INFO - Epoch: 08, Test Loss: 1.44669, Test Acc: 50.06%
2024-11-21 01:08:05,751 - INFO - Epoch: 09, unbiasedVICReg loss: 44.98172, Train Loss: 1.34608, Train Acc: 53.53%
2024-11-21 01:08:05,752 - INFO - Epoch: 09, Invariance loss: 0.00188
2024-11-21 01:08:05,752 - INFO - Epoch: 09, Variance loss: 0.92134
2024-11-21 01:08:05,752 - INFO - Epoch: 09, Covariance loss: 0.00564
2024-11-21 01:08:05,752 - INFO - Epoch: 09, Compare losses: 23.08637 == 44.98172
2024-11-21 01:08:06,635 - INFO - Epoch: 09, Optimizer LR: 0.24545796, Linear Optimizer LR: 0.00078125
2024-11-21 01:08:10,697 - INFO - Epoch: 09, Test Loss: 1.46126, Test Acc: 49.99%
2024-11-21 01:09:45,977 - INFO - Epoch: 10, unbiasedVICReg loss: 44.97894, Train Loss: 1.31512, Train Acc: 54.78%
2024-11-21 01:09:45,977 - INFO - Epoch: 10, Invariance loss: 0.00182
2024-11-21 01:09:45,977 - INFO - Epoch: 10, Variance loss: 0.92113
2024-11-21 01:09:45,977 - INFO - Epoch: 10, Covariance loss: 0.00568
2024-11-21 01:09:45,977 - INFO - Epoch: 10, Compare losses: 23.07941 == 44.97894
2024-11-21 01:09:46,936 - INFO - Epoch: 10, Optimizer LR: 0.26734797, Linear Optimizer LR: 0.00078125
2024-11-21 01:09:51,129 - INFO - Epoch: 10, Test Loss: 1.37760, Test Acc: 52.47%
2024-11-21 01:11:29,269 - INFO - Epoch: 11, unbiasedVICReg loss: 44.97678, Train Loss: 1.29058, Train Acc: 55.41%
2024-11-21 01:11:29,269 - INFO - Epoch: 11, Invariance loss: 0.00178
2024-11-21 01:11:29,269 - INFO - Epoch: 11, Variance loss: 0.92087
2024-11-21 01:11:29,269 - INFO - Epoch: 11, Covariance loss: 0.00574
2024-11-21 01:11:29,269 - INFO - Epoch: 11, Compare losses: 23.07179 == 44.97678
2024-11-21 01:11:30,119 - INFO - Epoch: 11, Optimizer LR: 0.01321515, Linear Optimizer LR: 0.00078125
2024-11-21 01:11:34,288 - INFO - Epoch: 11, Test Loss: 1.36071, Test Acc: 52.92%
2024-11-21 01:13:10,296 - INFO - Epoch: 12, unbiasedVICReg loss: 44.97412, Train Loss: 1.27414, Train Acc: 55.99%
2024-11-21 01:13:10,297 - INFO - Epoch: 12, Invariance loss: 0.00171
2024-11-21 01:13:10,297 - INFO - Epoch: 12, Variance loss: 0.92071
2024-11-21 01:13:10,297 - INFO - Epoch: 12, Covariance loss: 0.00576
2024-11-21 01:13:10,297 - INFO - Epoch: 12, Compare losses: 23.06635 == 44.97412
2024-11-21 01:13:11,146 - INFO - Epoch: 12, Optimizer LR: 0.36183485, Linear Optimizer LR: 0.00078125
2024-11-21 01:13:15,325 - INFO - Epoch: 12, Test Loss: 1.29352, Test Acc: 55.19%
2024-11-21 01:14:53,416 - INFO - Epoch: 13, unbiasedVICReg loss: 44.97201, Train Loss: 1.24898, Train Acc: 56.93%
2024-11-21 01:14:53,416 - INFO - Epoch: 13, Invariance loss: 0.00167
2024-11-21 01:14:53,416 - INFO - Epoch: 13, Variance loss: 0.92049
2024-11-21 01:14:53,416 - INFO - Epoch: 13, Covariance loss: 0.00581
2024-11-21 01:14:53,416 - INFO - Epoch: 13, Compare losses: 23.05970 == 44.97201
2024-11-21 01:14:54,279 - INFO - Epoch: 13, Optimizer LR: 0.10770203, Linear Optimizer LR: 0.00078125
2024-11-21 01:14:58,416 - INFO - Epoch: 13, Test Loss: 1.27885, Test Acc: 56.14%
2024-11-21 01:16:34,773 - INFO - Epoch: 14, unbiasedVICReg loss: 44.97046, Train Loss: 1.22866, Train Acc: 57.73%
2024-11-21 01:16:34,773 - INFO - Epoch: 14, Invariance loss: 0.00163
2024-11-21 01:16:34,773 - INFO - Epoch: 14, Variance loss: 0.92037
2024-11-21 01:16:34,773 - INFO - Epoch: 14, Covariance loss: 0.00582
2024-11-21 01:16:34,773 - INFO - Epoch: 14, Compare losses: 23.05593 == 44.97046
2024-11-21 01:16:35,636 - INFO - Epoch: 14, Optimizer LR: 0.12959204, Linear Optimizer LR: 0.00078125
2024-11-21 01:16:39,741 - INFO - Epoch: 14, Test Loss: 1.21145, Test Acc: 58.52%
2024-11-21 01:18:17,827 - INFO - Epoch: 15, unbiasedVICReg loss: 44.96901, Train Loss: 1.21133, Train Acc: 58.14%
2024-11-21 01:18:17,827 - INFO - Epoch: 15, Invariance loss: 0.00161
2024-11-21 01:18:17,827 - INFO - Epoch: 15, Variance loss: 0.92022
2024-11-21 01:18:17,827 - INFO - Epoch: 15, Covariance loss: 0.00585
2024-11-21 01:18:17,827 - INFO - Epoch: 15, Compare losses: 23.05158 == 44.96901
2024-11-21 01:18:18,639 - INFO - Epoch: 15, Optimizer LR: 0.35181059, Linear Optimizer LR: 0.00078125
2024-11-21 01:18:22,661 - INFO - Epoch: 15, Test Loss: 1.19051, Test Acc: 58.59%
2024-11-21 01:19:57,134 - INFO - Epoch: 16, unbiasedVICReg loss: 44.96693, Train Loss: 1.19222, Train Acc: 58.87%
2024-11-21 01:19:57,134 - INFO - Epoch: 16, Invariance loss: 0.00156
2024-11-21 01:19:57,134 - INFO - Epoch: 16, Variance loss: 0.92004
2024-11-21 01:19:57,134 - INFO - Epoch: 16, Covariance loss: 0.00589
2024-11-21 01:19:57,134 - INFO - Epoch: 16, Compare losses: 23.04595 == 44.96693
2024-11-21 01:19:57,963 - INFO - Epoch: 16, Optimizer LR: 0.00593987, Linear Optimizer LR: 0.00078125
2024-11-21 01:20:01,983 - INFO - Epoch: 16, Test Loss: 1.23867, Test Acc: 57.20%
2024-11-21 01:21:39,593 - INFO - Epoch: 17, unbiasedVICReg loss: 44.96595, Train Loss: 1.17475, Train Acc: 59.34%
2024-11-21 01:21:39,593 - INFO - Epoch: 17, Invariance loss: 0.00153
2024-11-21 01:21:39,593 - INFO - Epoch: 17, Variance loss: 0.91996
2024-11-21 01:21:39,593 - INFO - Epoch: 17, Covariance loss: 0.00590
2024-11-21 01:21:39,593 - INFO - Epoch: 17, Compare losses: 23.04333 == 44.96595
2024-11-21 01:21:40,475 - INFO - Epoch: 17, Optimizer LR: 0.28797913, Linear Optimizer LR: 0.00078125
2024-11-21 01:21:44,935 - INFO - Epoch: 17, Test Loss: 1.18888, Test Acc: 59.20%
2024-11-21 01:23:22,189 - INFO - Epoch: 18, unbiasedVICReg loss: 44.96436, Train Loss: 1.16986, Train Acc: 59.66%
2024-11-21 01:23:22,189 - INFO - Epoch: 18, Invariance loss: 0.00150
2024-11-21 01:23:22,189 - INFO - Epoch: 18, Variance loss: 0.91984
2024-11-21 01:23:22,189 - INFO - Epoch: 18, Covariance loss: 0.00592
2024-11-21 01:23:22,189 - INFO - Epoch: 18, Compare losses: 23.03962 == 44.96436
2024-11-21 01:23:23,060 - INFO - Epoch: 18, Optimizer LR: 0.22265431, Linear Optimizer LR: 0.00078125
2024-11-21 01:23:27,230 - INFO - Epoch: 18, Test Loss: 1.14796, Test Acc: 60.14%
2024-11-21 01:25:03,547 - INFO - Epoch: 19, unbiasedVICReg loss: 44.96295, Train Loss: 1.15968, Train Acc: 59.95%
2024-11-21 01:25:03,548 - INFO - Epoch: 19, Invariance loss: 0.00148
2024-11-21 01:25:03,548 - INFO - Epoch: 19, Variance loss: 0.91966
2024-11-21 01:25:03,548 - INFO - Epoch: 19, Covariance loss: 0.00596
2024-11-21 01:25:03,548 - INFO - Epoch: 19, Compare losses: 23.03450 == 44.96295
2024-11-21 01:25:04,387 - INFO - Epoch: 19, Optimizer LR: 0.03585454, Linear Optimizer LR: 0.00078125
2024-11-21 01:25:08,780 - INFO - Epoch: 19, Test Loss: 1.18316, Test Acc: 59.76%
2024-11-21 01:26:46,529 - INFO - Epoch: 20, unbiasedVICReg loss: 44.96157, Train Loss: 1.14156, Train Acc: 60.45%
2024-11-21 01:26:46,530 - INFO - Epoch: 20, Invariance loss: 0.00145
2024-11-21 01:26:46,530 - INFO - Epoch: 20, Variance loss: 0.91959
2024-11-21 01:26:46,530 - INFO - Epoch: 20, Covariance loss: 0.00596
2024-11-21 01:26:46,530 - INFO - Epoch: 20, Compare losses: 23.03190 == 44.96157
2024-11-21 01:26:47,396 - INFO - Epoch: 20, Optimizer LR: 0.37352170, Linear Optimizer LR: 0.00078125
2024-11-21 01:26:51,539 - INFO - Epoch: 20, Test Loss: 1.12818, Test Acc: 60.49%
2024-11-21 01:28:26,311 - INFO - Epoch: 21, unbiasedVICReg loss: 44.96124, Train Loss: 1.13224, Train Acc: 60.97%
2024-11-21 01:28:26,325 - INFO - Epoch: 21, Invariance loss: 0.00144
2024-11-21 01:28:26,325 - INFO - Epoch: 21, Variance loss: 0.91956
2024-11-21 01:28:26,326 - INFO - Epoch: 21, Covariance loss: 0.00597
2024-11-21 01:28:26,326 - INFO - Epoch: 21, Compare losses: 23.03111 == 44.96124
2024-11-21 01:28:27,217 - INFO - Epoch: 21, Optimizer LR: 0.06802394, Linear Optimizer LR: 0.00078125
2024-11-21 01:28:31,262 - INFO - Epoch: 21, Test Loss: 1.14805, Test Acc: 60.05%
2024-11-21 01:30:08,978 - INFO - Epoch: 22, unbiasedVICReg loss: 44.95968, Train Loss: 1.12281, Train Acc: 61.10%
2024-11-21 01:30:08,978 - INFO - Epoch: 22, Invariance loss: 0.00141
2024-11-21 01:30:08,978 - INFO - Epoch: 22, Variance loss: 0.91943
2024-11-21 01:30:08,978 - INFO - Epoch: 22, Covariance loss: 0.00599
2024-11-21 01:30:08,979 - INFO - Epoch: 22, Compare losses: 23.02691 == 44.95968
2024-11-21 01:30:09,812 - INFO - Epoch: 22, Optimizer LR: 0.17575335, Linear Optimizer LR: 0.00078125
2024-11-21 01:30:13,947 - INFO - Epoch: 22, Test Loss: 1.09455, Test Acc: 61.74%
2024-11-21 01:31:49,272 - INFO - Epoch: 23, unbiasedVICReg loss: 44.95898, Train Loss: 1.11722, Train Acc: 61.18%
2024-11-21 01:31:49,273 - INFO - Epoch: 23, Invariance loss: 0.00139
2024-11-21 01:31:49,273 - INFO - Epoch: 23, Variance loss: 0.91937
2024-11-21 01:31:49,273 - INFO - Epoch: 23, Covariance loss: 0.00600
2024-11-21 01:31:49,273 - INFO - Epoch: 23, Compare losses: 23.02509 == 44.95898
2024-11-21 01:31:50,122 - INFO - Epoch: 23, Optimizer LR: 0.32418839, Linear Optimizer LR: 0.00078125
2024-11-21 01:31:54,271 - INFO - Epoch: 23, Test Loss: 1.09544, Test Acc: 61.90%
2024-11-21 01:33:32,811 - INFO - Epoch: 24, unbiasedVICReg loss: 44.95799, Train Loss: 1.11059, Train Acc: 61.52%
2024-11-21 01:33:32,811 - INFO - Epoch: 24, Invariance loss: 0.00137
2024-11-21 01:33:32,811 - INFO - Epoch: 24, Variance loss: 0.91926
2024-11-21 01:33:32,811 - INFO - Epoch: 24, Covariance loss: 0.00602
2024-11-21 01:33:32,812 - INFO - Epoch: 24, Compare losses: 23.02193 == 44.95799
2024-11-21 01:33:33,697 - INFO - Epoch: 24, Optimizer LR: 0.00005000, Linear Optimizer LR: 0.00078125
2024-11-21 01:33:38,113 - INFO - Epoch: 24, Test Loss: 1.09517, Test Acc: 62.32%
2024-11-21 01:35:12,424 - INFO - Epoch: 25, unbiasedVICReg loss: 44.95694, Train Loss: 1.09923, Train Acc: 62.01%
2024-11-21 01:35:12,424 - INFO - Epoch: 25, Invariance loss: 0.00136
2024-11-21 01:35:12,424 - INFO - Epoch: 25, Variance loss: 0.91917
2024-11-21 01:35:12,424 - INFO - Epoch: 25, Covariance loss: 0.00604
2024-11-21 01:35:12,425 - INFO - Epoch: 25, Compare losses: 23.01935 == 44.95694
2024-11-21 01:35:13,275 - INFO - Epoch: 25, Optimizer LR: 0.32418839, Linear Optimizer LR: 0.00078125
2024-11-21 01:35:17,531 - INFO - Epoch: 25, Test Loss: 1.07299, Test Acc: 62.38%
2024-11-21 01:36:55,690 - INFO - Epoch: 26, unbiasedVICReg loss: 44.95603, Train Loss: 1.09056, Train Acc: 62.41%
2024-11-21 01:36:55,690 - INFO - Epoch: 26, Invariance loss: 0.00134
2024-11-21 01:36:55,690 - INFO - Epoch: 26, Variance loss: 0.91911
2024-11-21 01:36:55,690 - INFO - Epoch: 26, Covariance loss: 0.00605
2024-11-21 01:36:55,690 - INFO - Epoch: 26, Compare losses: 23.01734 == 44.95603
2024-11-21 01:36:56,527 - INFO - Epoch: 26, Optimizer LR: 0.17575335, Linear Optimizer LR: 0.00078125
2024-11-21 01:37:00,741 - INFO - Epoch: 26, Test Loss: 1.08801, Test Acc: 62.55%
2024-11-21 01:38:35,002 - INFO - Epoch: 27, unbiasedVICReg loss: 44.95512, Train Loss: 1.08746, Train Acc: 62.28%
2024-11-21 01:38:35,003 - INFO - Epoch: 27, Invariance loss: 0.00132
2024-11-21 01:38:35,003 - INFO - Epoch: 27, Variance loss: 0.91901
2024-11-21 01:38:35,003 - INFO - Epoch: 27, Covariance loss: 0.00607
2024-11-21 01:38:35,003 - INFO - Epoch: 27, Compare losses: 23.01437 == 44.95512
2024-11-21 01:38:35,837 - INFO - Epoch: 27, Optimizer LR: 0.06802394, Linear Optimizer LR: 0.00078125
2024-11-21 01:38:40,033 - INFO - Epoch: 27, Test Loss: 1.09545, Test Acc: 61.89%
2024-11-21 01:40:18,209 - INFO - Epoch: 28, unbiasedVICReg loss: 44.95476, Train Loss: 1.07867, Train Acc: 62.57%
2024-11-21 01:40:18,209 - INFO - Epoch: 28, Invariance loss: 0.00131
2024-11-21 01:40:18,209 - INFO - Epoch: 28, Variance loss: 0.91900
2024-11-21 01:40:18,209 - INFO - Epoch: 28, Covariance loss: 0.00607
2024-11-21 01:40:18,209 - INFO - Epoch: 28, Compare losses: 23.01383 == 44.95476
2024-11-21 01:40:19,092 - INFO - Epoch: 28, Optimizer LR: 0.37352170, Linear Optimizer LR: 0.00078125
2024-11-21 01:40:23,189 - INFO - Epoch: 28, Test Loss: 1.05218, Test Acc: 63.04%
2024-11-21 01:41:57,938 - INFO - Epoch: 29, unbiasedVICReg loss: 44.95405, Train Loss: 1.07322, Train Acc: 62.70%
2024-11-21 01:41:57,938 - INFO - Epoch: 29, Invariance loss: 0.00130
2024-11-21 01:41:57,938 - INFO - Epoch: 29, Variance loss: 0.91892
2024-11-21 01:41:57,938 - INFO - Epoch: 29, Covariance loss: 0.00608
2024-11-21 01:41:57,938 - INFO - Epoch: 29, Compare losses: 23.01149 == 44.95405
2024-11-21 01:41:58,805 - INFO - Epoch: 29, Optimizer LR: 0.03585454, Linear Optimizer LR: 0.00078125
2024-11-21 01:42:02,889 - INFO - Epoch: 29, Test Loss: 1.02418, Test Acc: 64.47%
2024-11-21 01:43:40,546 - INFO - Epoch: 30, unbiasedVICReg loss: 44.95327, Train Loss: 1.06885, Train Acc: 62.82%
2024-11-21 01:43:40,546 - INFO - Epoch: 30, Invariance loss: 0.00128
2024-11-21 01:43:40,546 - INFO - Epoch: 30, Variance loss: 0.91885
2024-11-21 01:43:40,546 - INFO - Epoch: 30, Covariance loss: 0.00609
2024-11-21 01:43:40,547 - INFO - Epoch: 30, Compare losses: 23.00947 == 44.95327
2024-11-21 01:43:41,382 - INFO - Epoch: 30, Optimizer LR: 0.22265431, Linear Optimizer LR: 0.00078125
2024-11-21 01:43:45,442 - INFO - Epoch: 30, Test Loss: 1.06250, Test Acc: 63.50%
2024-11-21 01:45:20,630 - INFO - Epoch: 31, unbiasedVICReg loss: 44.95272, Train Loss: 1.05921, Train Acc: 63.28%
2024-11-21 01:45:20,630 - INFO - Epoch: 31, Invariance loss: 0.00128
2024-11-21 01:45:20,630 - INFO - Epoch: 31, Variance loss: 0.91882
2024-11-21 01:45:20,630 - INFO - Epoch: 31, Covariance loss: 0.00609
2024-11-21 01:45:20,630 - INFO - Epoch: 31, Compare losses: 23.00849 == 44.95272
2024-11-21 01:45:21,482 - INFO - Epoch: 31, Optimizer LR: 0.28797913, Linear Optimizer LR: 0.00078125
2024-11-21 01:45:25,611 - INFO - Epoch: 31, Test Loss: 1.04840, Test Acc: 63.51%
2024-11-21 01:47:03,681 - INFO - Epoch: 32, unbiasedVICReg loss: 44.95210, Train Loss: 1.05211, Train Acc: 63.51%
2024-11-21 01:47:03,682 - INFO - Epoch: 32, Invariance loss: 0.00126
2024-11-21 01:47:03,682 - INFO - Epoch: 32, Variance loss: 0.91874
2024-11-21 01:47:03,682 - INFO - Epoch: 32, Covariance loss: 0.00611
2024-11-21 01:47:03,682 - INFO - Epoch: 32, Compare losses: 23.00632 == 44.95210
2024-11-21 01:47:04,545 - INFO - Epoch: 32, Optimizer LR: 0.00593987, Linear Optimizer LR: 0.00078125
2024-11-21 01:47:08,774 - INFO - Epoch: 32, Test Loss: 1.04706, Test Acc: 63.77%
2024-11-21 01:48:43,813 - INFO - Epoch: 33, unbiasedVICReg loss: 44.95113, Train Loss: 1.04814, Train Acc: 63.55%
2024-11-21 01:48:43,814 - INFO - Epoch: 33, Invariance loss: 0.00124
2024-11-21 01:48:43,814 - INFO - Epoch: 33, Variance loss: 0.91868
2024-11-21 01:48:43,814 - INFO - Epoch: 33, Covariance loss: 0.00612
2024-11-21 01:48:43,814 - INFO - Epoch: 33, Compare losses: 23.00418 == 44.95113
2024-11-21 01:48:44,625 - INFO - Epoch: 33, Optimizer LR: 0.35181059, Linear Optimizer LR: 0.00078125
2024-11-21 01:48:48,809 - INFO - Epoch: 33, Test Loss: 0.98850, Test Acc: 65.72%
2024-11-21 01:50:26,751 - INFO - Epoch: 34, unbiasedVICReg loss: 44.95086, Train Loss: 1.03845, Train Acc: 63.83%
2024-11-21 01:50:26,751 - INFO - Epoch: 34, Invariance loss: 0.00123
2024-11-21 01:50:26,751 - INFO - Epoch: 34, Variance loss: 0.91867
2024-11-21 01:50:26,751 - INFO - Epoch: 34, Covariance loss: 0.00613
2024-11-21 01:50:26,751 - INFO - Epoch: 34, Compare losses: 23.00360 == 44.95086
2024-11-21 01:50:27,629 - INFO - Epoch: 34, Optimizer LR: 0.12959204, Linear Optimizer LR: 0.00078125
2024-11-21 01:50:31,784 - INFO - Epoch: 34, Test Loss: 1.05543, Test Acc: 62.90%
2024-11-21 01:52:07,680 - INFO - Epoch: 35, unbiasedVICReg loss: 44.95037, Train Loss: 1.04118, Train Acc: 63.65%
2024-11-21 01:52:07,680 - INFO - Epoch: 35, Invariance loss: 0.00122
2024-11-21 01:52:07,680 - INFO - Epoch: 35, Variance loss: 0.91862
2024-11-21 01:52:07,680 - INFO - Epoch: 35, Covariance loss: 0.00613
2024-11-21 01:52:07,680 - INFO - Epoch: 35, Compare losses: 23.00216 == 44.95037
2024-11-21 01:52:08,506 - INFO - Epoch: 35, Optimizer LR: 0.10770203, Linear Optimizer LR: 0.00078125
2024-11-21 01:52:12,615 - INFO - Epoch: 35, Test Loss: 1.07564, Test Acc: 62.05%
2024-11-21 01:53:51,397 - INFO - Epoch: 36, unbiasedVICReg loss: 44.94960, Train Loss: 1.03396, Train Acc: 64.24%
2024-11-21 01:53:51,397 - INFO - Epoch: 36, Invariance loss: 0.00121
2024-11-21 01:53:51,397 - INFO - Epoch: 36, Variance loss: 0.91855
2024-11-21 01:53:51,397 - INFO - Epoch: 36, Covariance loss: 0.00615
2024-11-21 01:53:51,398 - INFO - Epoch: 36, Compare losses: 23.00025 == 44.94960
2024-11-21 01:53:52,258 - INFO - Epoch: 36, Optimizer LR: 0.36183485, Linear Optimizer LR: 0.00078125
2024-11-21 01:53:56,410 - INFO - Epoch: 36, Test Loss: 0.99369, Test Acc: 65.26%
2024-11-21 01:55:27,031 - INFO - Epoch: 37, unbiasedVICReg loss: 44.94881, Train Loss: 1.03028, Train Acc: 64.23%
2024-11-21 01:55:27,031 - INFO - Epoch: 37, Invariance loss: 0.00119
2024-11-21 01:55:27,031 - INFO - Epoch: 37, Variance loss: 0.91848
2024-11-21 01:55:27,031 - INFO - Epoch: 37, Covariance loss: 0.00616
2024-11-21 01:55:27,031 - INFO - Epoch: 37, Compare losses: 22.99802 == 44.94881
2024-11-21 01:55:27,854 - INFO - Epoch: 37, Optimizer LR: 0.01321515, Linear Optimizer LR: 0.00078125
2024-11-21 01:55:31,993 - INFO - Epoch: 37, Test Loss: 0.99387, Test Acc: 65.51%
2024-11-21 01:57:08,646 - INFO - Epoch: 38, unbiasedVICReg loss: 44.94828, Train Loss: 1.02286, Train Acc: 64.36%
2024-11-21 01:57:08,646 - INFO - Epoch: 38, Invariance loss: 0.00118
2024-11-21 01:57:08,646 - INFO - Epoch: 38, Variance loss: 0.91847
2024-11-21 01:57:08,646 - INFO - Epoch: 38, Covariance loss: 0.00616
2024-11-21 01:57:08,646 - INFO - Epoch: 38, Compare losses: 22.99739 == 44.94828
2024-11-21 01:57:09,514 - INFO - Epoch: 38, Optimizer LR: 0.26734797, Linear Optimizer LR: 0.00078125
2024-11-21 01:57:13,537 - INFO - Epoch: 38, Test Loss: 0.98096, Test Acc: 65.88%
2024-11-21 01:58:48,466 - INFO - Epoch: 39, unbiasedVICReg loss: 44.94763, Train Loss: 1.01786, Train Acc: 64.58%
2024-11-21 01:58:48,466 - INFO - Epoch: 39, Invariance loss: 0.00117
2024-11-21 01:58:48,466 - INFO - Epoch: 39, Variance loss: 0.91839
2024-11-21 01:58:48,466 - INFO - Epoch: 39, Covariance loss: 0.00617
2024-11-21 01:58:48,466 - INFO - Epoch: 39, Compare losses: 22.99506 == 44.94763
2024-11-21 01:58:49,291 - INFO - Epoch: 39, Optimizer LR: 0.24545796, Linear Optimizer LR: 0.00078125
2024-11-21 01:58:53,401 - INFO - Epoch: 39, Test Loss: 0.99968, Test Acc: 65.57%
2024-11-21 02:00:28,151 - INFO - Epoch: 40, unbiasedVICReg loss: 44.94746, Train Loss: 1.01261, Train Acc: 64.96%
2024-11-21 02:00:28,152 - INFO - Epoch: 40, Invariance loss: 0.00117
2024-11-21 02:00:28,152 - INFO - Epoch: 40, Variance loss: 0.91836
2024-11-21 02:00:28,152 - INFO - Epoch: 40, Covariance loss: 0.00618
2024-11-21 02:00:28,152 - INFO - Epoch: 40, Compare losses: 22.99442 == 44.94746
2024-11-21 02:00:29,015 - INFO - Epoch: 40, Optimizer LR: 0.02323941, Linear Optimizer LR: 0.00078125
2024-11-21 02:00:33,045 - INFO - Epoch: 40, Test Loss: 0.99776, Test Acc: 65.37%
2024-11-21 02:02:04,384 - INFO - Epoch: 41, unbiasedVICReg loss: 44.94743, Train Loss: 1.01402, Train Acc: 64.95%
2024-11-21 02:02:04,385 - INFO - Epoch: 41, Invariance loss: 0.00117
2024-11-21 02:02:04,385 - INFO - Epoch: 41, Variance loss: 0.91834
2024-11-21 02:02:04,385 - INFO - Epoch: 41, Covariance loss: 0.00618
2024-11-21 02:02:04,385 - INFO - Epoch: 41, Compare losses: 22.99407 == 44.94743
2024-11-21 02:02:05,237 - INFO - Epoch: 41, Optimizer LR: 0.36911013, Linear Optimizer LR: 0.00078125
2024-11-21 02:02:09,390 - INFO - Epoch: 41, Test Loss: 0.98229, Test Acc: 65.76%
2024-11-21 02:03:43,495 - INFO - Epoch: 42, unbiasedVICReg loss: 44.94679, Train Loss: 1.00668, Train Acc: 65.30%
2024-11-21 02:03:43,495 - INFO - Epoch: 42, Invariance loss: 0.00116
2024-11-21 02:03:43,495 - INFO - Epoch: 42, Variance loss: 0.91829
2024-11-21 02:03:43,495 - INFO - Epoch: 42, Covariance loss: 0.00619
2024-11-21 02:03:43,495 - INFO - Epoch: 42, Compare losses: 22.99226 == 44.94679
2024-11-21 02:03:44,325 - INFO - Epoch: 42, Optimizer LR: 0.08707087, Linear Optimizer LR: 0.00078125
2024-11-21 02:03:48,405 - INFO - Epoch: 42, Test Loss: 0.96507, Test Acc: 66.40%
2024-11-21 02:05:22,676 - INFO - Epoch: 43, unbiasedVICReg loss: 44.94641, Train Loss: 1.00143, Train Acc: 65.11%
2024-11-21 02:05:22,676 - INFO - Epoch: 43, Invariance loss: 0.00115
2024-11-21 02:05:22,676 - INFO - Epoch: 43, Variance loss: 0.91828
2024-11-21 02:05:22,676 - INFO - Epoch: 43, Covariance loss: 0.00619
2024-11-21 02:05:22,676 - INFO - Epoch: 43, Compare losses: 22.99193 == 44.94641
2024-11-21 02:05:23,517 - INFO - Epoch: 43, Optimizer LR: 0.15239569, Linear Optimizer LR: 0.00078125
2024-11-21 02:05:27,610 - INFO - Epoch: 43, Test Loss: 0.96225, Test Acc: 66.02%
2024-11-21 02:07:01,929 - INFO - Epoch: 44, unbiasedVICReg loss: 44.94582, Train Loss: 1.00280, Train Acc: 65.03%
2024-11-21 02:07:01,929 - INFO - Epoch: 44, Invariance loss: 0.00113
2024-11-21 02:07:01,929 - INFO - Epoch: 44, Variance loss: 0.91825
2024-11-21 02:07:01,929 - INFO - Epoch: 44, Covariance loss: 0.00620
2024-11-21 02:07:01,930 - INFO - Epoch: 44, Compare losses: 22.99073 == 44.94582
2024-11-21 02:07:02,793 - INFO - Epoch: 44, Optimizer LR: 0.33919546, Linear Optimizer LR: 0.00078125
2024-11-21 02:07:06,856 - INFO - Epoch: 44, Test Loss: 0.95380, Test Acc: 66.80%
2024-11-21 02:08:38,019 - INFO - Epoch: 45, unbiasedVICReg loss: 44.94552, Train Loss: 0.99751, Train Acc: 65.31%
2024-11-21 02:08:38,020 - INFO - Epoch: 45, Invariance loss: 0.00112
2024-11-21 02:08:38,020 - INFO - Epoch: 45, Variance loss: 0.91821
2024-11-21 02:08:38,020 - INFO - Epoch: 45, Covariance loss: 0.00620
2024-11-21 02:08:38,020 - INFO - Epoch: 45, Compare losses: 22.98958 == 44.94552
2024-11-21 02:08:38,866 - INFO - Epoch: 45, Optimizer LR: 0.00152830, Linear Optimizer LR: 0.00078125
2024-11-21 02:08:43,016 - INFO - Epoch: 45, Test Loss: 0.94400, Test Acc: 67.08%
2024-11-21 02:10:18,387 - INFO - Epoch: 46, unbiasedVICReg loss: 44.94537, Train Loss: 0.99412, Train Acc: 65.49%
2024-11-21 02:10:18,387 - INFO - Epoch: 46, Invariance loss: 0.00112
2024-11-21 02:10:18,387 - INFO - Epoch: 46, Variance loss: 0.91822
2024-11-21 02:10:18,387 - INFO - Epoch: 46, Covariance loss: 0.00620
2024-11-21 02:10:18,387 - INFO - Epoch: 46, Compare losses: 22.98976 == 44.94537
2024-11-21 02:10:19,229 - INFO - Epoch: 46, Optimizer LR: 0.30702606, Linear Optimizer LR: 0.00078125
2024-11-21 02:10:23,384 - INFO - Epoch: 46, Test Loss: 0.96385, Test Acc: 65.72%
2024-11-21 02:11:58,019 - INFO - Epoch: 47, unbiasedVICReg loss: 44.94486, Train Loss: 0.98882, Train Acc: 65.64%
2024-11-21 02:11:58,019 - INFO - Epoch: 47, Invariance loss: 0.00112
2024-11-21 02:11:58,019 - INFO - Epoch: 47, Variance loss: 0.91815
2024-11-21 02:11:58,020 - INFO - Epoch: 47, Covariance loss: 0.00621
2024-11-21 02:11:58,020 - INFO - Epoch: 47, Compare losses: 22.98783 == 44.94486
2024-11-21 02:11:58,879 - INFO - Epoch: 47, Optimizer LR: 0.19929665, Linear Optimizer LR: 0.00078125
2024-11-21 02:12:03,263 - INFO - Epoch: 47, Test Loss: 0.99365, Test Acc: 65.92%
2024-11-21 02:13:36,865 - INFO - Epoch: 48, unbiasedVICReg loss: 44.94475, Train Loss: 0.98959, Train Acc: 65.77%
2024-11-21 02:13:36,866 - INFO - Epoch: 48, Invariance loss: 0.00111
2024-11-21 02:13:36,866 - INFO - Epoch: 48, Variance loss: 0.91813
2024-11-21 02:13:36,866 - INFO - Epoch: 48, Covariance loss: 0.00622
2024-11-21 02:13:36,866 - INFO - Epoch: 48, Compare losses: 22.98737 == 44.94475
2024-11-21 02:13:37,716 - INFO - Epoch: 48, Optimizer LR: 0.05086161, Linear Optimizer LR: 0.00078125
2024-11-21 02:13:41,984 - INFO - Epoch: 48, Test Loss: 0.97491, Test Acc: 66.06%
2024-11-21 02:15:16,156 - INFO - Epoch: 49, unbiasedVICReg loss: 44.94439, Train Loss: 0.98600, Train Acc: 65.89%
2024-11-21 02:15:16,156 - INFO - Epoch: 49, Invariance loss: 0.00111
2024-11-21 02:15:16,156 - INFO - Epoch: 49, Variance loss: 0.91813
2024-11-21 02:15:16,157 - INFO - Epoch: 49, Covariance loss: 0.00622
2024-11-21 02:15:16,157 - INFO - Epoch: 49, Compare losses: 22.98700 == 44.94439
2024-11-21 02:15:17,048 - INFO - Epoch: 49, Optimizer LR: 0.37500000, Linear Optimizer LR: 0.00078125
2024-11-21 02:15:21,210 - INFO - Epoch: 49, Test Loss: 0.93674, Test Acc: 67.43%
