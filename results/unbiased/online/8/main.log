2024-11-21 04:45:28,357 - INFO - Checkpoint directory: ./results/unbiased/online/8
2024-11-21 04:45:28,358 - INFO - Configuration:
2024-11-21 04:45:28,358 - INFO - sim_coeff: 25.0
2024-11-21 04:45:28,358 - INFO - std_coeff: 25
2024-11-21 04:45:28,358 - INFO - cov_coeff: 1
2024-11-21 04:45:28,358 - INFO - batch_sizes: [256, 128, 64, 32, 16, 8]
2024-11-21 04:45:28,358 - INFO - num_epochs: 50
2024-11-21 04:45:28,358 - INFO - max_lr_vicreg: 0.01657281518405971
2024-11-21 04:45:28,358 - INFO - momentum: 0.9
2024-11-21 04:45:28,358 - INFO - weight_decay: 0.0001
2024-11-21 04:45:28,358 - INFO - final_lr_schedule_value: 2.209708691207961e-06
2024-11-21 04:45:28,358 - INFO - warmup_epochs: 5
2024-11-21 04:45:28,359 - INFO - batch_size_evaluate: 8
2024-11-21 04:45:28,359 - INFO - num_eval_epochs: 50
2024-11-21 04:45:28,359 - INFO - max_lr_linear: 0.000152587890625
2024-11-21 04:45:28,359 - INFO - linear_momentum: 0.9
2024-11-21 04:45:28,359 - INFO - linear_weight_decay: 0.0
2024-11-21 04:45:28,359 - INFO - backbone: resnet18
2024-11-21 04:45:28,359 - INFO - augs_train_type: lightly
2024-11-21 04:45:28,359 - INFO - augs_eval_enable: False
2024-11-21 04:45:28,359 - INFO - num_layers: 3
2024-11-21 04:45:28,359 - INFO - projection_head_dims: [512, 2048]
2024-11-21 04:45:28,359 - INFO - probe: online
2024-11-21 04:45:28,359 - INFO - loss: unbiased
2024-11-21 04:45:28,359 - INFO - batch_size_sharing: True
2024-11-21 04:45:28,359 - INFO - scale_lr_batched: True
2024-11-21 04:45:28,359 - INFO - batch_size: 8
2024-11-21 04:45:28,359 - INFO - checkpoint_dir: ./results/unbiased/online/8
2024-11-21 04:45:28,359 - INFO - Running with batch_size=8
2024-11-21 04:45:28,359 - INFO - Using device: cuda
2024-11-21 04:45:28,360 - INFO - Setting up experiment...
2024-11-21 04:45:28,360 - INFO - Using ResNet18 backbone
2024-11-21 04:45:28,625 - INFO - Using unbiased VICReg loss
2024-11-21 04:45:28,625 - INFO - Setting up datasets and dataloaders
2024-11-21 04:45:29,869 - INFO - Created dataloaders with batch size 8 and evaluate 8
2024-11-21 04:45:29,870 - INFO - Created optimizers with learning rates: vicreg=0.01657281518405971, linear=0.000152587890625
2024-11-21 04:45:29,871 - INFO - Loaded checkpoints: vicreg_epoch=0, linear_epoch=0
2024-11-21 04:45:29,871 - INFO - Starting from epoch vicreg_start:0
2024-11-21 04:45:29,871 - INFO - Writing visualization data to TensorBoard
2024-11-21 04:45:30,993 - INFO - Successfully wrote visualization data to TensorBoard
2024-11-21 04:45:31,037 - INFO - Beginning train + evaluate for online probing
2024-11-21 04:45:31,038 - INFO - Continuing training from epoch 0 to 50
2024-11-21 04:51:07,460 - INFO - Epoch: 00, unbiasedVICReg loss: 513.52539, Train Loss: 2.28606, Train Acc: 12.27%
2024-11-21 04:51:07,461 - INFO - Epoch: 00, Invariance loss: 0.08932
2024-11-21 04:51:07,461 - INFO - Epoch: 00, Variance loss: 0.80489
2024-11-21 04:51:07,461 - INFO - Epoch: 00, Covariance loss: 3.10306
2024-11-21 04:51:07,461 - INFO - Epoch: 00, Compare losses: 25.45829 == 513.52539
2024-11-21 04:51:07,651 - INFO - Epoch: 00, Optimizer LR: 0.00000221, Linear Optimizer LR: 0.00000153
2024-11-21 04:51:14,462 - INFO - Epoch: 00, Test Loss: 2.31337, Test Acc: 9.95%
2024-11-21 04:56:50,489 - INFO - Epoch: 01, unbiasedVICReg loss: 45.21373, Train Loss: 2.26490, Train Acc: 13.36%
2024-11-21 04:56:50,489 - INFO - Epoch: 01, Invariance loss: 0.00119
2024-11-21 04:56:50,489 - INFO - Epoch: 01, Variance loss: 0.96951
2024-11-21 04:56:50,489 - INFO - Epoch: 01, Covariance loss: 0.00057
2024-11-21 04:56:50,490 - INFO - Epoch: 01, Compare losses: 24.26796 == 45.21373
2024-11-21 04:56:51,337 - INFO - Epoch: 01, Optimizer LR: 0.01657282, Linear Optimizer LR: 0.00000153
2024-11-21 04:56:58,279 - INFO - Epoch: 01, Test Loss: 2.31923, Test Acc: 9.79%
2024-11-21 05:02:33,807 - INFO - Epoch: 02, unbiasedVICReg loss: 45.20938, Train Loss: 2.24471, Train Acc: 14.14%
2024-11-21 05:02:33,808 - INFO - Epoch: 02, Invariance loss: 0.00108
2024-11-21 05:02:33,808 - INFO - Epoch: 02, Variance loss: 0.96875
2024-11-21 05:02:33,808 - INFO - Epoch: 02, Covariance loss: 0.00063
2024-11-21 05:02:33,808 - INFO - Epoch: 02, Compare losses: 24.24644 == 45.20938
2024-11-21 05:02:34,673 - INFO - Epoch: 02, Optimizer LR: 0.00000221, Linear Optimizer LR: 0.00000153
2024-11-21 05:02:41,412 - INFO - Epoch: 02, Test Loss: 2.25628, Test Acc: 13.02%
2024-11-21 05:08:17,379 - INFO - Epoch: 03, unbiasedVICReg loss: 45.20457, Train Loss: 2.23141, Train Acc: 14.79%
2024-11-21 05:08:17,380 - INFO - Epoch: 03, Invariance loss: 0.00099
2024-11-21 05:08:17,380 - INFO - Epoch: 03, Variance loss: 0.96777
2024-11-21 05:08:17,380 - INFO - Epoch: 03, Covariance loss: 0.00070
2024-11-21 05:08:17,380 - INFO - Epoch: 03, Compare losses: 24.21962 == 45.20457
2024-11-21 05:08:18,246 - INFO - Epoch: 03, Optimizer LR: 0.01657282, Linear Optimizer LR: 0.00000153
2024-11-21 05:08:24,829 - INFO - Epoch: 03, Test Loss: 3.16959, Test Acc: 11.68%
2024-11-21 05:14:00,312 - INFO - Epoch: 04, unbiasedVICReg loss: 45.20088, Train Loss: 2.21943, Train Acc: 16.43%
2024-11-21 05:14:00,313 - INFO - Epoch: 04, Invariance loss: 0.00091
2024-11-21 05:14:00,313 - INFO - Epoch: 04, Variance loss: 0.96712
2024-11-21 05:14:00,313 - INFO - Epoch: 04, Covariance loss: 0.00075
2024-11-21 05:14:00,313 - INFO - Epoch: 04, Compare losses: 24.20159 == 45.20088
2024-11-21 05:14:01,171 - INFO - Epoch: 04, Optimizer LR: 0.00000221, Linear Optimizer LR: 0.00000153
2024-11-21 05:14:07,688 - INFO - Epoch: 04, Test Loss: 2.20797, Test Acc: 14.97%
2024-11-21 05:19:44,073 - INFO - Epoch: 05, unbiasedVICReg loss: 45.19841, Train Loss: 2.20893, Train Acc: 18.18%
2024-11-21 05:19:44,074 - INFO - Epoch: 05, Invariance loss: 0.00086
2024-11-21 05:19:44,074 - INFO - Epoch: 05, Variance loss: 0.96660
2024-11-21 05:19:44,074 - INFO - Epoch: 05, Covariance loss: 0.00080
2024-11-21 05:19:44,074 - INFO - Epoch: 05, Compare losses: 24.18727 == 45.19841
2024-11-21 05:19:44,945 - INFO - Epoch: 05, Optimizer LR: 0.01657282, Linear Optimizer LR: 0.00000153
2024-11-21 05:19:51,730 - INFO - Epoch: 05, Test Loss: 2.18058, Test Acc: 15.79%
2024-11-21 05:25:30,159 - INFO - Epoch: 06, unbiasedVICReg loss: 45.19634, Train Loss: 2.20252, Train Acc: 19.28%
2024-11-21 05:25:30,160 - INFO - Epoch: 06, Invariance loss: 0.00082
2024-11-21 05:25:30,160 - INFO - Epoch: 06, Variance loss: 0.96619
2024-11-21 05:25:30,160 - INFO - Epoch: 06, Covariance loss: 0.00083
2024-11-21 05:25:30,160 - INFO - Epoch: 06, Compare losses: 24.17607 == 45.19634
2024-11-21 05:25:31,007 - INFO - Epoch: 06, Optimizer LR: 0.00000221, Linear Optimizer LR: 0.00000153
2024-11-21 05:25:37,564 - INFO - Epoch: 06, Test Loss: 2.67130, Test Acc: 12.39%
2024-11-21 05:31:13,693 - INFO - Epoch: 07, unbiasedVICReg loss: 45.19472, Train Loss: 2.19984, Train Acc: 19.72%
2024-11-21 05:31:13,694 - INFO - Epoch: 07, Invariance loss: 0.00078
2024-11-21 05:31:13,694 - INFO - Epoch: 07, Variance loss: 0.96591
2024-11-21 05:31:13,694 - INFO - Epoch: 07, Covariance loss: 0.00085
2024-11-21 05:31:13,694 - INFO - Epoch: 07, Compare losses: 24.16805 == 45.19472
2024-11-21 05:31:14,555 - INFO - Epoch: 07, Optimizer LR: 0.01657282, Linear Optimizer LR: 0.00000153
2024-11-21 05:31:21,486 - INFO - Epoch: 07, Test Loss: 2.28634, Test Acc: 14.48%
2024-11-21 05:36:59,940 - INFO - Epoch: 08, unbiasedVICReg loss: 45.19353, Train Loss: 2.19298, Train Acc: 20.90%
2024-11-21 05:36:59,940 - INFO - Epoch: 08, Invariance loss: 0.00075
2024-11-21 05:36:59,941 - INFO - Epoch: 08, Variance loss: 0.96564
2024-11-21 05:36:59,941 - INFO - Epoch: 08, Covariance loss: 0.00087
2024-11-21 05:36:59,941 - INFO - Epoch: 08, Compare losses: 24.16064 == 45.19353
2024-11-21 05:37:00,800 - INFO - Epoch: 08, Optimizer LR: 0.00000221, Linear Optimizer LR: 0.00000153
2024-11-21 05:37:07,947 - INFO - Epoch: 08, Test Loss: 2.30251, Test Acc: 14.45%
2024-11-21 05:42:45,649 - INFO - Epoch: 09, unbiasedVICReg loss: 45.19228, Train Loss: 2.18697, Train Acc: 21.48%
2024-11-21 05:42:45,649 - INFO - Epoch: 09, Invariance loss: 0.00072
2024-11-21 05:42:45,649 - INFO - Epoch: 09, Variance loss: 0.96545
2024-11-21 05:42:45,649 - INFO - Epoch: 09, Covariance loss: 0.00089
2024-11-21 05:42:45,649 - INFO - Epoch: 09, Compare losses: 24.15494 == 45.19228
2024-11-21 05:42:46,504 - INFO - Epoch: 09, Optimizer LR: 0.01657282, Linear Optimizer LR: 0.00000153
2024-11-21 05:42:53,804 - INFO - Epoch: 09, Test Loss: 2.31394, Test Acc: 14.92%
2024-11-21 05:48:31,943 - INFO - Epoch: 10, unbiasedVICReg loss: 45.19144, Train Loss: 2.18180, Train Acc: 22.60%
2024-11-21 05:48:31,943 - INFO - Epoch: 10, Invariance loss: 0.00070
2024-11-21 05:48:31,943 - INFO - Epoch: 10, Variance loss: 0.96531
2024-11-21 05:48:31,943 - INFO - Epoch: 10, Covariance loss: 0.00090
2024-11-21 05:48:31,943 - INFO - Epoch: 10, Compare losses: 24.15098 == 45.19144
2024-11-21 05:48:32,782 - INFO - Epoch: 10, Optimizer LR: 0.00000221, Linear Optimizer LR: 0.00000153
2024-11-21 05:48:39,900 - INFO - Epoch: 10, Test Loss: 2.63625, Test Acc: 12.62%
2024-11-21 05:54:18,086 - INFO - Epoch: 11, unbiasedVICReg loss: 45.19050, Train Loss: 2.17755, Train Acc: 23.20%
2024-11-21 05:54:18,086 - INFO - Epoch: 11, Invariance loss: 0.00068
2024-11-21 05:54:18,086 - INFO - Epoch: 11, Variance loss: 0.96516
2024-11-21 05:54:18,086 - INFO - Epoch: 11, Covariance loss: 0.00091
2024-11-21 05:54:18,087 - INFO - Epoch: 11, Compare losses: 24.14688 == 45.19050
2024-11-21 05:54:18,924 - INFO - Epoch: 11, Optimizer LR: 0.01657282, Linear Optimizer LR: 0.00000153
2024-11-21 05:54:25,432 - INFO - Epoch: 11, Test Loss: 2.48288, Test Acc: 12.78%
2024-11-21 06:00:03,382 - INFO - Epoch: 12, unbiasedVICReg loss: 45.18975, Train Loss: 2.17313, Train Acc: 23.52%
2024-11-21 06:00:03,383 - INFO - Epoch: 12, Invariance loss: 0.00066
2024-11-21 06:00:03,383 - INFO - Epoch: 12, Variance loss: 0.96504
2024-11-21 06:00:03,383 - INFO - Epoch: 12, Covariance loss: 0.00092
2024-11-21 06:00:03,383 - INFO - Epoch: 12, Compare losses: 24.14335 == 45.18975
2024-11-21 06:00:04,239 - INFO - Epoch: 12, Optimizer LR: 0.00000221, Linear Optimizer LR: 0.00000153
2024-11-21 06:00:10,776 - INFO - Epoch: 12, Test Loss: 2.49894, Test Acc: 14.33%
2024-11-21 06:05:46,385 - INFO - Epoch: 13, unbiasedVICReg loss: 45.18906, Train Loss: 2.16717, Train Acc: 24.43%
2024-11-21 06:05:46,386 - INFO - Epoch: 13, Invariance loss: 0.00064
2024-11-21 06:05:46,386 - INFO - Epoch: 13, Variance loss: 0.96489
2024-11-21 06:05:46,386 - INFO - Epoch: 13, Covariance loss: 0.00093
2024-11-21 06:05:46,386 - INFO - Epoch: 13, Compare losses: 24.13928 == 45.18906
2024-11-21 06:05:47,247 - INFO - Epoch: 13, Optimizer LR: 0.01657282, Linear Optimizer LR: 0.00000153
2024-11-21 06:05:53,904 - INFO - Epoch: 13, Test Loss: 3.17941, Test Acc: 12.41%
2024-11-21 06:11:29,708 - INFO - Epoch: 14, unbiasedVICReg loss: 45.18863, Train Loss: 2.16217, Train Acc: 25.04%
2024-11-21 06:11:29,708 - INFO - Epoch: 14, Invariance loss: 0.00063
2024-11-21 06:11:29,708 - INFO - Epoch: 14, Variance loss: 0.96480
2024-11-21 06:11:29,708 - INFO - Epoch: 14, Covariance loss: 0.00094
2024-11-21 06:11:29,708 - INFO - Epoch: 14, Compare losses: 24.13665 == 45.18863
2024-11-21 06:11:30,560 - INFO - Epoch: 14, Optimizer LR: 0.00000221, Linear Optimizer LR: 0.00000153
2024-11-21 06:11:37,218 - INFO - Epoch: 14, Test Loss: 2.60488, Test Acc: 13.89%
2024-11-21 06:17:13,681 - INFO - Epoch: 15, unbiasedVICReg loss: 45.18794, Train Loss: 2.15894, Train Acc: 25.45%
2024-11-21 06:17:13,682 - INFO - Epoch: 15, Invariance loss: 0.00061
2024-11-21 06:17:13,682 - INFO - Epoch: 15, Variance loss: 0.96473
2024-11-21 06:17:13,682 - INFO - Epoch: 15, Covariance loss: 0.00095
2024-11-21 06:17:13,682 - INFO - Epoch: 15, Compare losses: 24.13427 == 45.18794
2024-11-21 06:17:14,542 - INFO - Epoch: 15, Optimizer LR: 0.01657282, Linear Optimizer LR: 0.00000153
2024-11-21 06:17:21,405 - INFO - Epoch: 15, Test Loss: 2.55861, Test Acc: 14.07%
2024-11-21 06:22:56,026 - INFO - Epoch: 16, unbiasedVICReg loss: 45.18723, Train Loss: 2.15283, Train Acc: 25.78%
2024-11-21 06:22:56,026 - INFO - Epoch: 16, Invariance loss: 0.00059
2024-11-21 06:22:56,026 - INFO - Epoch: 16, Variance loss: 0.96461
2024-11-21 06:22:56,026 - INFO - Epoch: 16, Covariance loss: 0.00096
2024-11-21 06:22:56,026 - INFO - Epoch: 16, Compare losses: 24.13090 == 45.18723
2024-11-21 06:22:56,888 - INFO - Epoch: 16, Optimizer LR: 0.00000221, Linear Optimizer LR: 0.00000153
2024-11-21 06:23:03,827 - INFO - Epoch: 16, Test Loss: 2.23864, Test Acc: 16.63%
2024-11-21 06:28:40,066 - INFO - Epoch: 17, unbiasedVICReg loss: 45.18678, Train Loss: 2.14746, Train Acc: 26.37%
2024-11-21 06:28:40,067 - INFO - Epoch: 17, Invariance loss: 0.00058
2024-11-21 06:28:40,067 - INFO - Epoch: 17, Variance loss: 0.96455
2024-11-21 06:28:40,067 - INFO - Epoch: 17, Covariance loss: 0.00096
2024-11-21 06:28:40,067 - INFO - Epoch: 17, Compare losses: 24.12907 == 45.18678
2024-11-21 06:28:40,929 - INFO - Epoch: 17, Optimizer LR: 0.01657282, Linear Optimizer LR: 0.00000153
2024-11-21 06:28:47,666 - INFO - Epoch: 17, Test Loss: 2.49824, Test Acc: 14.61%
2024-11-21 06:34:23,626 - INFO - Epoch: 18, unbiasedVICReg loss: 45.18621, Train Loss: 2.14073, Train Acc: 26.72%
2024-11-21 06:34:23,626 - INFO - Epoch: 18, Invariance loss: 0.00056
2024-11-21 06:34:23,626 - INFO - Epoch: 18, Variance loss: 0.96444
2024-11-21 06:34:23,627 - INFO - Epoch: 18, Covariance loss: 0.00097
2024-11-21 06:34:23,627 - INFO - Epoch: 18, Compare losses: 24.12589 == 45.18621
2024-11-21 06:34:24,493 - INFO - Epoch: 18, Optimizer LR: 0.00000221, Linear Optimizer LR: 0.00000153
2024-11-21 06:34:31,161 - INFO - Epoch: 18, Test Loss: 2.57977, Test Acc: 12.89%
2024-11-21 06:40:06,922 - INFO - Epoch: 19, unbiasedVICReg loss: 45.18580, Train Loss: 2.13318, Train Acc: 27.03%
2024-11-21 06:40:06,922 - INFO - Epoch: 19, Invariance loss: 0.00055
2024-11-21 06:40:06,923 - INFO - Epoch: 19, Variance loss: 0.96438
2024-11-21 06:40:06,923 - INFO - Epoch: 19, Covariance loss: 0.00098
2024-11-21 06:40:06,923 - INFO - Epoch: 19, Compare losses: 24.12435 == 45.18580
2024-11-21 06:40:07,781 - INFO - Epoch: 19, Optimizer LR: 0.01657282, Linear Optimizer LR: 0.00000153
2024-11-21 06:40:14,676 - INFO - Epoch: 19, Test Loss: 2.45369, Test Acc: 16.25%
2024-11-21 06:45:49,806 - INFO - Epoch: 20, unbiasedVICReg loss: 45.18517, Train Loss: 2.12723, Train Acc: 27.22%
2024-11-21 06:45:49,806 - INFO - Epoch: 20, Invariance loss: 0.00053
2024-11-21 06:45:49,806 - INFO - Epoch: 20, Variance loss: 0.96429
2024-11-21 06:45:49,806 - INFO - Epoch: 20, Covariance loss: 0.00099
2024-11-21 06:45:49,806 - INFO - Epoch: 20, Compare losses: 24.12151 == 45.18517
2024-11-21 06:45:50,667 - INFO - Epoch: 20, Optimizer LR: 0.00000221, Linear Optimizer LR: 0.00000153
2024-11-21 06:45:57,161 - INFO - Epoch: 20, Test Loss: 2.64249, Test Acc: 13.58%
2024-11-21 06:51:33,580 - INFO - Epoch: 21, unbiasedVICReg loss: 45.18483, Train Loss: 2.12277, Train Acc: 27.41%
2024-11-21 06:51:33,580 - INFO - Epoch: 21, Invariance loss: 0.00052
2024-11-21 06:51:33,581 - INFO - Epoch: 21, Variance loss: 0.96424
2024-11-21 06:51:33,581 - INFO - Epoch: 21, Covariance loss: 0.00099
2024-11-21 06:51:33,581 - INFO - Epoch: 21, Compare losses: 24.11996 == 45.18483
2024-11-21 06:51:34,427 - INFO - Epoch: 21, Optimizer LR: 0.01657282, Linear Optimizer LR: 0.00000153
2024-11-21 06:51:41,012 - INFO - Epoch: 21, Test Loss: 2.20576, Test Acc: 17.75%
2024-11-21 06:56:29,153 - INFO - Epoch: 22, unbiasedVICReg loss: 45.18456, Train Loss: 2.11829, Train Acc: 27.30%
2024-11-21 06:56:29,153 - INFO - Epoch: 22, Invariance loss: 0.00052
2024-11-21 06:56:29,154 - INFO - Epoch: 22, Variance loss: 0.96417
2024-11-21 06:56:29,154 - INFO - Epoch: 22, Covariance loss: 0.00100
2024-11-21 06:56:29,154 - INFO - Epoch: 22, Compare losses: 24.11811 == 45.18456
2024-11-21 06:56:30,015 - INFO - Epoch: 22, Optimizer LR: 0.00000221, Linear Optimizer LR: 0.00000153
2024-11-21 06:56:35,861 - INFO - Epoch: 22, Test Loss: 2.22741, Test Acc: 18.81%
2024-11-21 07:00:20,544 - INFO - Epoch: 23, unbiasedVICReg loss: 45.18403, Train Loss: 2.11444, Train Acc: 28.15%
2024-11-21 07:00:20,545 - INFO - Epoch: 23, Invariance loss: 0.00050
2024-11-21 07:00:20,545 - INFO - Epoch: 23, Variance loss: 0.96408
2024-11-21 07:00:20,545 - INFO - Epoch: 23, Covariance loss: 0.00101
2024-11-21 07:00:20,545 - INFO - Epoch: 23, Compare losses: 24.11559 == 45.18403
2024-11-21 07:00:21,371 - INFO - Epoch: 23, Optimizer LR: 0.01657282, Linear Optimizer LR: 0.00000153
2024-11-21 07:00:27,341 - INFO - Epoch: 23, Test Loss: 2.22624, Test Acc: 18.89%
2024-11-21 07:04:06,194 - INFO - Epoch: 24, unbiasedVICReg loss: 45.18382, Train Loss: 2.11144, Train Acc: 28.32%
2024-11-21 07:04:06,194 - INFO - Epoch: 24, Invariance loss: 0.00049
2024-11-21 07:04:06,194 - INFO - Epoch: 24, Variance loss: 0.96407
2024-11-21 07:04:06,195 - INFO - Epoch: 24, Covariance loss: 0.00101
2024-11-21 07:04:06,195 - INFO - Epoch: 24, Compare losses: 24.11521 == 45.18382
2024-11-21 07:04:07,042 - INFO - Epoch: 24, Optimizer LR: 0.00000221, Linear Optimizer LR: 0.00000153
2024-11-21 07:04:13,469 - INFO - Epoch: 24, Test Loss: 2.14576, Test Acc: 22.24%
2024-11-21 07:08:01,579 - INFO - Epoch: 25, unbiasedVICReg loss: 45.18343, Train Loss: 2.10537, Train Acc: 29.01%
2024-11-21 07:08:01,579 - INFO - Epoch: 25, Invariance loss: 0.00049
2024-11-21 07:08:01,579 - INFO - Epoch: 25, Variance loss: 0.96400
2024-11-21 07:08:01,579 - INFO - Epoch: 25, Covariance loss: 0.00101
2024-11-21 07:08:01,579 - INFO - Epoch: 25, Compare losses: 24.11319 == 45.18343
2024-11-21 07:08:02,448 - INFO - Epoch: 25, Optimizer LR: 0.01657282, Linear Optimizer LR: 0.00000153
2024-11-21 07:08:08,944 - INFO - Epoch: 25, Test Loss: 2.15659, Test Acc: 22.25%
2024-11-21 07:11:58,176 - INFO - Epoch: 26, unbiasedVICReg loss: 45.18309, Train Loss: 2.10425, Train Acc: 28.69%
2024-11-21 07:11:58,176 - INFO - Epoch: 26, Invariance loss: 0.00048
2024-11-21 07:11:58,176 - INFO - Epoch: 26, Variance loss: 0.96394
2024-11-21 07:11:58,176 - INFO - Epoch: 26, Covariance loss: 0.00102
2024-11-21 07:11:58,176 - INFO - Epoch: 26, Compare losses: 24.11155 == 45.18309
2024-11-21 07:11:59,120 - INFO - Epoch: 26, Optimizer LR: 0.00000221, Linear Optimizer LR: 0.00000153
2024-11-21 07:12:05,636 - INFO - Epoch: 26, Test Loss: 2.16015, Test Acc: 22.28%
2024-11-21 07:15:59,331 - INFO - Epoch: 27, unbiasedVICReg loss: 45.18257, Train Loss: 2.10128, Train Acc: 29.04%
2024-11-21 07:15:59,331 - INFO - Epoch: 27, Invariance loss: 0.00046
2024-11-21 07:15:59,331 - INFO - Epoch: 27, Variance loss: 0.96388
2024-11-21 07:15:59,331 - INFO - Epoch: 27, Covariance loss: 0.00102
2024-11-21 07:15:59,331 - INFO - Epoch: 27, Compare losses: 24.10967 == 45.18257
2024-11-21 07:16:00,221 - INFO - Epoch: 27, Optimizer LR: 0.01657282, Linear Optimizer LR: 0.00000153
2024-11-21 07:16:06,550 - INFO - Epoch: 27, Test Loss: 2.17024, Test Acc: 21.23%
2024-11-21 07:19:56,505 - INFO - Epoch: 28, unbiasedVICReg loss: 45.18238, Train Loss: 2.09903, Train Acc: 29.11%
2024-11-21 07:19:56,505 - INFO - Epoch: 28, Invariance loss: 0.00046
2024-11-21 07:19:56,505 - INFO - Epoch: 28, Variance loss: 0.96385
2024-11-21 07:19:56,505 - INFO - Epoch: 28, Covariance loss: 0.00103
2024-11-21 07:19:56,505 - INFO - Epoch: 28, Compare losses: 24.10868 == 45.18238
2024-11-21 07:19:57,416 - INFO - Epoch: 28, Optimizer LR: 0.00000221, Linear Optimizer LR: 0.00000153
2024-11-21 07:20:04,161 - INFO - Epoch: 28, Test Loss: 2.21879, Test Acc: 19.61%
2024-11-21 07:23:47,379 - INFO - Epoch: 29, unbiasedVICReg loss: 45.18193, Train Loss: 2.09704, Train Acc: 29.54%
2024-11-21 07:23:47,379 - INFO - Epoch: 29, Invariance loss: 0.00045
2024-11-21 07:23:47,379 - INFO - Epoch: 29, Variance loss: 0.96380
2024-11-21 07:23:47,379 - INFO - Epoch: 29, Covariance loss: 0.00103
2024-11-21 07:23:47,379 - INFO - Epoch: 29, Compare losses: 24.10722 == 45.18193
2024-11-21 07:23:48,266 - INFO - Epoch: 29, Optimizer LR: 0.01657282, Linear Optimizer LR: 0.00000153
2024-11-21 07:23:54,577 - INFO - Epoch: 29, Test Loss: 2.38395, Test Acc: 17.06%
2024-11-21 07:27:41,670 - INFO - Epoch: 30, unbiasedVICReg loss: 45.18179, Train Loss: 2.09344, Train Acc: 30.02%
2024-11-21 07:27:41,670 - INFO - Epoch: 30, Invariance loss: 0.00044
2024-11-21 07:27:41,670 - INFO - Epoch: 30, Variance loss: 0.96377
2024-11-21 07:27:41,670 - INFO - Epoch: 30, Covariance loss: 0.00103
2024-11-21 07:27:41,670 - INFO - Epoch: 30, Compare losses: 24.10632 == 45.18179
2024-11-21 07:27:42,555 - INFO - Epoch: 30, Optimizer LR: 0.00000221, Linear Optimizer LR: 0.00000153
2024-11-21 07:27:48,824 - INFO - Epoch: 30, Test Loss: 2.11303, Test Acc: 31.26%
2024-11-21 07:31:34,093 - INFO - Epoch: 31, unbiasedVICReg loss: 45.18134, Train Loss: 2.08806, Train Acc: 30.39%
2024-11-21 07:31:34,094 - INFO - Epoch: 31, Invariance loss: 0.00043
2024-11-21 07:31:34,094 - INFO - Epoch: 31, Variance loss: 0.96373
2024-11-21 07:31:34,094 - INFO - Epoch: 31, Covariance loss: 0.00104
2024-11-21 07:31:34,094 - INFO - Epoch: 31, Compare losses: 24.10509 == 45.18134
2024-11-21 07:31:34,949 - INFO - Epoch: 31, Optimizer LR: 0.01657282, Linear Optimizer LR: 0.00000153
2024-11-21 07:31:41,229 - INFO - Epoch: 31, Test Loss: 2.09987, Test Acc: 26.45%
2024-11-21 07:35:26,168 - INFO - Epoch: 32, unbiasedVICReg loss: 45.18123, Train Loss: 2.08766, Train Acc: 30.63%
2024-11-21 07:35:26,169 - INFO - Epoch: 32, Invariance loss: 0.00043
2024-11-21 07:35:26,169 - INFO - Epoch: 32, Variance loss: 0.96371
2024-11-21 07:35:26,169 - INFO - Epoch: 32, Covariance loss: 0.00104
2024-11-21 07:35:26,169 - INFO - Epoch: 32, Compare losses: 24.10458 == 45.18123
2024-11-21 07:35:27,045 - INFO - Epoch: 32, Optimizer LR: 0.00000221, Linear Optimizer LR: 0.00000153
2024-11-21 07:35:33,492 - INFO - Epoch: 32, Test Loss: 2.18484, Test Acc: 22.68%
2024-11-21 07:39:18,641 - INFO - Epoch: 33, unbiasedVICReg loss: 45.18103, Train Loss: 2.08640, Train Acc: 31.03%
2024-11-21 07:39:18,641 - INFO - Epoch: 33, Invariance loss: 0.00043
2024-11-21 07:39:18,642 - INFO - Epoch: 33, Variance loss: 0.96368
2024-11-21 07:39:18,642 - INFO - Epoch: 33, Covariance loss: 0.00104
2024-11-21 07:39:18,642 - INFO - Epoch: 33, Compare losses: 24.10380 == 45.18103
2024-11-21 07:39:19,586 - INFO - Epoch: 33, Optimizer LR: 0.01657282, Linear Optimizer LR: 0.00000153
2024-11-21 07:39:26,027 - INFO - Epoch: 33, Test Loss: 2.10955, Test Acc: 26.49%
2024-11-21 07:43:10,662 - INFO - Epoch: 34, unbiasedVICReg loss: 45.18066, Train Loss: 2.08594, Train Acc: 30.82%
2024-11-21 07:43:10,663 - INFO - Epoch: 34, Invariance loss: 0.00042
2024-11-21 07:43:10,663 - INFO - Epoch: 34, Variance loss: 0.96364
2024-11-21 07:43:10,663 - INFO - Epoch: 34, Covariance loss: 0.00104
2024-11-21 07:43:10,663 - INFO - Epoch: 34, Compare losses: 24.10246 == 45.18066
2024-11-21 07:43:11,541 - INFO - Epoch: 34, Optimizer LR: 0.00000221, Linear Optimizer LR: 0.00000153
2024-11-21 07:43:17,644 - INFO - Epoch: 34, Test Loss: 2.09340, Test Acc: 26.10%
2024-11-21 07:46:57,909 - INFO - Epoch: 35, unbiasedVICReg loss: 45.18047, Train Loss: 2.08414, Train Acc: 31.09%
2024-11-21 07:46:57,910 - INFO - Epoch: 35, Invariance loss: 0.00042
2024-11-21 07:46:57,910 - INFO - Epoch: 35, Variance loss: 0.96360
2024-11-21 07:46:57,910 - INFO - Epoch: 35, Covariance loss: 0.00105
2024-11-21 07:46:57,910 - INFO - Epoch: 35, Compare losses: 24.10135 == 45.18047
2024-11-21 07:46:58,758 - INFO - Epoch: 35, Optimizer LR: 0.01657282, Linear Optimizer LR: 0.00000153
2024-11-21 07:47:05,233 - INFO - Epoch: 35, Test Loss: 2.12255, Test Acc: 24.48%
2024-11-21 07:50:59,807 - INFO - Epoch: 36, unbiasedVICReg loss: 45.18020, Train Loss: 2.08170, Train Acc: 31.69%
2024-11-21 07:50:59,807 - INFO - Epoch: 36, Invariance loss: 0.00041
2024-11-21 07:50:59,807 - INFO - Epoch: 36, Variance loss: 0.96357
2024-11-21 07:50:59,807 - INFO - Epoch: 36, Covariance loss: 0.00105
2024-11-21 07:50:59,807 - INFO - Epoch: 36, Compare losses: 24.10036 == 45.18020
2024-11-21 07:51:00,683 - INFO - Epoch: 36, Optimizer LR: 0.00000221, Linear Optimizer LR: 0.00000153
2024-11-21 07:51:07,172 - INFO - Epoch: 36, Test Loss: 2.11668, Test Acc: 24.46%
2024-11-21 07:54:53,670 - INFO - Epoch: 37, unbiasedVICReg loss: 45.18011, Train Loss: 2.08000, Train Acc: 31.50%
2024-11-21 07:54:53,671 - INFO - Epoch: 37, Invariance loss: 0.00041
2024-11-21 07:54:53,671 - INFO - Epoch: 37, Variance loss: 0.96352
2024-11-21 07:54:53,671 - INFO - Epoch: 37, Covariance loss: 0.00105
2024-11-21 07:54:53,671 - INFO - Epoch: 37, Compare losses: 24.09937 == 45.18011
2024-11-21 07:54:54,530 - INFO - Epoch: 37, Optimizer LR: 0.01657282, Linear Optimizer LR: 0.00000153
2024-11-21 07:55:00,442 - INFO - Epoch: 37, Test Loss: 2.12618, Test Acc: 25.52%
2024-11-21 07:58:37,084 - INFO - Epoch: 38, unbiasedVICReg loss: 45.17992, Train Loss: 2.07983, Train Acc: 31.64%
2024-11-21 07:58:37,084 - INFO - Epoch: 38, Invariance loss: 0.00040
2024-11-21 07:58:37,084 - INFO - Epoch: 38, Variance loss: 0.96350
2024-11-21 07:58:37,084 - INFO - Epoch: 38, Covariance loss: 0.00106
2024-11-21 07:58:37,085 - INFO - Epoch: 38, Compare losses: 24.09864 == 45.17992
2024-11-21 07:58:37,696 - INFO - Epoch: 38, Optimizer LR: 0.00000221, Linear Optimizer LR: 0.00000153
2024-11-21 07:58:43,658 - INFO - Epoch: 38, Test Loss: 2.07011, Test Acc: 30.30%
2024-11-21 08:02:21,857 - INFO - Epoch: 39, unbiasedVICReg loss: 45.17973, Train Loss: 2.07725, Train Acc: 32.07%
2024-11-21 08:02:21,858 - INFO - Epoch: 39, Invariance loss: 0.00040
2024-11-21 08:02:21,858 - INFO - Epoch: 39, Variance loss: 0.96348
2024-11-21 08:02:21,858 - INFO - Epoch: 39, Covariance loss: 0.00106
2024-11-21 08:02:21,858 - INFO - Epoch: 39, Compare losses: 24.09796 == 45.17973
2024-11-21 08:02:22,720 - INFO - Epoch: 39, Optimizer LR: 0.01657282, Linear Optimizer LR: 0.00000153
2024-11-21 08:02:28,744 - INFO - Epoch: 39, Test Loss: 2.09344, Test Acc: 26.43%
2024-11-21 08:05:50,573 - INFO - Epoch: 40, unbiasedVICReg loss: 45.17947, Train Loss: 2.07668, Train Acc: 32.20%
2024-11-21 08:05:50,573 - INFO - Epoch: 40, Invariance loss: 0.00039
2024-11-21 08:05:50,573 - INFO - Epoch: 40, Variance loss: 0.96345
2024-11-21 08:05:50,574 - INFO - Epoch: 40, Covariance loss: 0.00106
2024-11-21 08:05:50,574 - INFO - Epoch: 40, Compare losses: 24.09722 == 45.17947
2024-11-21 08:05:51,432 - INFO - Epoch: 40, Optimizer LR: 0.00000221, Linear Optimizer LR: 0.00000153
2024-11-21 08:05:57,734 - INFO - Epoch: 40, Test Loss: 2.08585, Test Acc: 28.08%
2024-11-21 08:09:23,746 - INFO - Epoch: 41, unbiasedVICReg loss: 45.17933, Train Loss: 2.07813, Train Acc: 32.17%
2024-11-21 08:09:23,746 - INFO - Epoch: 41, Invariance loss: 0.00039
2024-11-21 08:09:23,746 - INFO - Epoch: 41, Variance loss: 0.96343
2024-11-21 08:09:23,747 - INFO - Epoch: 41, Covariance loss: 0.00106
2024-11-21 08:09:23,747 - INFO - Epoch: 41, Compare losses: 24.09659 == 45.17933
2024-11-21 08:09:24,614 - INFO - Epoch: 41, Optimizer LR: 0.01657282, Linear Optimizer LR: 0.00000153
2024-11-21 08:09:30,982 - INFO - Epoch: 41, Test Loss: 2.10294, Test Acc: 26.27%
2024-11-21 08:12:56,145 - INFO - Epoch: 42, unbiasedVICReg loss: 45.17920, Train Loss: 2.07392, Train Acc: 32.08%
2024-11-21 08:12:56,146 - INFO - Epoch: 42, Invariance loss: 0.00038
2024-11-21 08:12:56,146 - INFO - Epoch: 42, Variance loss: 0.96341
2024-11-21 08:12:56,146 - INFO - Epoch: 42, Covariance loss: 0.00106
2024-11-21 08:12:56,146 - INFO - Epoch: 42, Compare losses: 24.09581 == 45.17920
2024-11-21 08:12:57,026 - INFO - Epoch: 42, Optimizer LR: 0.00000221, Linear Optimizer LR: 0.00000153
2024-11-21 08:13:03,183 - INFO - Epoch: 42, Test Loss: 2.08079, Test Acc: 28.73%
2024-11-21 08:16:29,869 - INFO - Epoch: 43, unbiasedVICReg loss: 45.17893, Train Loss: 2.07398, Train Acc: 32.35%
2024-11-21 08:16:29,869 - INFO - Epoch: 43, Invariance loss: 0.00038
2024-11-21 08:16:29,869 - INFO - Epoch: 43, Variance loss: 0.96338
2024-11-21 08:16:29,870 - INFO - Epoch: 43, Covariance loss: 0.00107
2024-11-21 08:16:29,870 - INFO - Epoch: 43, Compare losses: 24.09506 == 45.17893
2024-11-21 08:16:30,757 - INFO - Epoch: 43, Optimizer LR: 0.01657282, Linear Optimizer LR: 0.00000153
2024-11-21 08:16:38,249 - INFO - Epoch: 43, Test Loss: 2.09851, Test Acc: 26.44%
2024-11-21 08:20:06,143 - INFO - Epoch: 44, unbiasedVICReg loss: 45.17884, Train Loss: 2.07106, Train Acc: 32.27%
2024-11-21 08:20:06,143 - INFO - Epoch: 44, Invariance loss: 0.00038
2024-11-21 08:20:06,143 - INFO - Epoch: 44, Variance loss: 0.96338
2024-11-21 08:20:06,143 - INFO - Epoch: 44, Covariance loss: 0.00107
2024-11-21 08:20:06,144 - INFO - Epoch: 44, Compare losses: 24.09495 == 45.17884
2024-11-21 08:20:07,017 - INFO - Epoch: 44, Optimizer LR: 0.00000221, Linear Optimizer LR: 0.00000153
2024-11-21 08:20:15,060 - INFO - Epoch: 44, Test Loss: 2.08877, Test Acc: 30.18%
2024-11-21 08:23:39,933 - INFO - Epoch: 45, unbiasedVICReg loss: 45.17878, Train Loss: 2.07142, Train Acc: 32.16%
2024-11-21 08:23:39,933 - INFO - Epoch: 45, Invariance loss: 0.00038
2024-11-21 08:23:39,933 - INFO - Epoch: 45, Variance loss: 0.96335
2024-11-21 08:23:39,934 - INFO - Epoch: 45, Covariance loss: 0.00107
2024-11-21 08:23:39,934 - INFO - Epoch: 45, Compare losses: 24.09421 == 45.17878
2024-11-21 08:23:41,074 - INFO - Epoch: 45, Optimizer LR: 0.01657282, Linear Optimizer LR: 0.00000153
2024-11-21 08:23:47,636 - INFO - Epoch: 45, Test Loss: 2.08733, Test Acc: 29.20%
2024-11-21 08:27:14,832 - INFO - Epoch: 46, unbiasedVICReg loss: 45.17853, Train Loss: 2.06744, Train Acc: 32.54%
2024-11-21 08:27:14,833 - INFO - Epoch: 46, Invariance loss: 0.00037
2024-11-21 08:27:14,833 - INFO - Epoch: 46, Variance loss: 0.96331
2024-11-21 08:27:14,833 - INFO - Epoch: 46, Covariance loss: 0.00107
2024-11-21 08:27:14,833 - INFO - Epoch: 46, Compare losses: 24.09321 == 45.17853
2024-11-21 08:27:15,715 - INFO - Epoch: 46, Optimizer LR: 0.00000221, Linear Optimizer LR: 0.00000153
2024-11-21 08:27:21,647 - INFO - Epoch: 46, Test Loss: 2.07431, Test Acc: 30.14%
2024-11-21 08:30:48,850 - INFO - Epoch: 47, unbiasedVICReg loss: 45.17846, Train Loss: 2.06820, Train Acc: 32.51%
2024-11-21 08:30:48,850 - INFO - Epoch: 47, Invariance loss: 0.00037
2024-11-21 08:30:48,851 - INFO - Epoch: 47, Variance loss: 0.96331
2024-11-21 08:30:48,851 - INFO - Epoch: 47, Covariance loss: 0.00107
2024-11-21 08:30:48,851 - INFO - Epoch: 47, Compare losses: 24.09297 == 45.17846
2024-11-21 08:30:49,760 - INFO - Epoch: 47, Optimizer LR: 0.01657282, Linear Optimizer LR: 0.00000153
2024-11-21 08:30:55,770 - INFO - Epoch: 47, Test Loss: 2.09174, Test Acc: 27.96%
2024-11-21 08:34:18,750 - INFO - Epoch: 48, unbiasedVICReg loss: 45.17818, Train Loss: 2.06895, Train Acc: 32.24%
2024-11-21 08:34:18,750 - INFO - Epoch: 48, Invariance loss: 0.00036
2024-11-21 08:34:18,751 - INFO - Epoch: 48, Variance loss: 0.96328
2024-11-21 08:34:18,751 - INFO - Epoch: 48, Covariance loss: 0.00108
2024-11-21 08:34:18,751 - INFO - Epoch: 48, Compare losses: 24.09213 == 45.17818
2024-11-21 08:34:19,641 - INFO - Epoch: 48, Optimizer LR: 0.00000221, Linear Optimizer LR: 0.00000153
2024-11-21 08:34:25,595 - INFO - Epoch: 48, Test Loss: 2.05947, Test Acc: 33.49%
2024-11-21 08:37:49,603 - INFO - Epoch: 49, unbiasedVICReg loss: 45.17824, Train Loss: 2.06921, Train Acc: 32.40%
2024-11-21 08:37:49,604 - INFO - Epoch: 49, Invariance loss: 0.00036
2024-11-21 08:37:49,604 - INFO - Epoch: 49, Variance loss: 0.96328
2024-11-21 08:37:49,604 - INFO - Epoch: 49, Covariance loss: 0.00107
2024-11-21 08:37:49,604 - INFO - Epoch: 49, Compare losses: 24.09212 == 45.17824
2024-11-21 08:37:50,489 - INFO - Epoch: 49, Optimizer LR: 0.01657282, Linear Optimizer LR: 0.00000153
2024-11-21 08:37:56,617 - INFO - Epoch: 49, Test Loss: 2.06084, Test Acc: 35.13%
