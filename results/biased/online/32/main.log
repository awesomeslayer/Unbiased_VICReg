2024-11-20 21:41:43,355 - INFO - Checkpoint directory: ./results/biased/online/32
2024-11-20 21:41:43,355 - INFO - Configuration:
2024-11-20 21:41:43,356 - INFO - sim_coeff: 25.0
2024-11-20 21:41:43,356 - INFO - std_coeff: 25
2024-11-20 21:41:43,356 - INFO - cov_coeff: 1
2024-11-20 21:41:43,356 - INFO - batch_sizes: [256, 128, 64, 32, 16, 8]
2024-11-20 21:41:43,357 - INFO - num_epochs: 50
2024-11-20 21:41:43,357 - INFO - max_lr_vicreg: 0.37500000000000006
2024-11-20 21:41:43,357 - INFO - momentum: 0.9
2024-11-20 21:41:43,357 - INFO - weight_decay: 0.0001
2024-11-20 21:41:43,357 - INFO - final_lr_schedule_value: 0.00012500000000000003
2024-11-20 21:41:43,357 - INFO - warmup_epochs: 5
2024-11-20 21:41:43,357 - INFO - batch_size_evaluate: 32
2024-11-20 21:41:43,357 - INFO - num_eval_epochs: 50
2024-11-20 21:41:43,357 - INFO - max_lr_linear: 0.078125
2024-11-20 21:41:43,357 - INFO - linear_momentum: 0.9
2024-11-20 21:41:43,357 - INFO - linear_weight_decay: 0.0
2024-11-20 21:41:43,358 - INFO - backbone: resnet18
2024-11-20 21:41:43,358 - INFO - augs_train_type: lightly
2024-11-20 21:41:43,358 - INFO - augs_eval_enable: False
2024-11-20 21:41:43,358 - INFO - num_layers: 3
2024-11-20 21:41:43,358 - INFO - projection_head_dims: [512, 2048]
2024-11-20 21:41:43,358 - INFO - probe: online
2024-11-20 21:41:43,358 - INFO - loss: biased
2024-11-20 21:41:43,358 - INFO - batch_size_sharing: True
2024-11-20 21:41:43,358 - INFO - scale_lr_batched: True
2024-11-20 21:41:43,358 - INFO - batch_size: 32
2024-11-20 21:41:43,358 - INFO - checkpoint_dir: ./results/biased/online/32
2024-11-20 21:41:43,359 - INFO - Running with batch_size=32
2024-11-20 21:41:43,359 - INFO - Using device: cuda
2024-11-20 21:41:43,360 - INFO - Setting up experiment...
2024-11-20 21:41:43,360 - INFO - Using ResNet18 backbone
2024-11-20 21:41:43,619 - INFO - Using biased VICReg loss
2024-11-20 21:41:43,619 - INFO - Setting up datasets and dataloaders
2024-11-20 21:41:44,849 - INFO - Created dataloaders with batch size 32 and evaluate 32
2024-11-20 21:41:44,851 - INFO - Created optimizers with learning rates: vicreg=0.37500000000000006, linear=0.078125
2024-11-20 21:41:44,851 - INFO - Loaded checkpoints: vicreg_epoch=0, linear_epoch=0
2024-11-20 21:41:44,851 - INFO - Starting from epoch vicreg_start:0
2024-11-20 21:41:44,851 - INFO - Writing visualization data to TensorBoard
2024-11-20 21:41:45,861 - INFO - Successfully wrote visualization data to TensorBoard
2024-11-20 21:41:45,895 - INFO - Beginning train + evaluate for online probing
2024-11-20 21:41:45,895 - INFO - Continuing training from epoch 0 to 50
2024-11-20 21:42:45,771 - INFO - Epoch: 00, biasedVICReg loss: 20.71275, Train Loss: 2.64202, Train Acc: 33.14%
2024-11-20 21:42:45,771 - INFO - Epoch: 00, Invariance loss: 0.04893
2024-11-20 21:42:45,771 - INFO - Epoch: 00, Variance loss: 0.73662
2024-11-20 21:42:45,771 - INFO - Epoch: 00, Covariance loss: 1.07404
2024-11-20 21:42:45,772 - INFO - Epoch: 00, Compare losses: 20.71275 == 20.71275
2024-11-20 21:42:45,950 - INFO - Epoch: 00, Optimizer LR: 0.05092644, Linear Optimizer LR: 0.00078125
2024-11-20 21:42:49,995 - INFO - Epoch: 00, Test Loss: 2.30283, Test Acc: 21.71%
2024-11-20 21:43:49,449 - INFO - Epoch: 01, biasedVICReg loss: 20.08139, Train Loss: 1.62382, Train Acc: 40.98%
2024-11-20 21:43:49,449 - INFO - Epoch: 01, Invariance loss: 0.03879
2024-11-20 21:43:49,449 - INFO - Epoch: 01, Variance loss: 0.71245
2024-11-20 21:43:49,449 - INFO - Epoch: 01, Covariance loss: 1.30055
2024-11-20 21:43:49,450 - INFO - Epoch: 01, Compare losses: 20.08140 == 20.08139
2024-11-20 21:43:50,350 - INFO - Epoch: 01, Optimizer LR: 0.19933180, Linear Optimizer LR: 0.00078125
2024-11-20 21:43:54,531 - INFO - Epoch: 01, Test Loss: 2.02545, Test Acc: 27.12%
2024-11-20 21:44:56,328 - INFO - Epoch: 02, biasedVICReg loss: 19.84573, Train Loss: 1.51853, Train Acc: 44.96%
2024-11-20 21:44:56,328 - INFO - Epoch: 02, Invariance loss: 0.03447
2024-11-20 21:44:56,328 - INFO - Epoch: 02, Variance loss: 0.70287
2024-11-20 21:44:56,328 - INFO - Epoch: 02, Covariance loss: 1.41243
2024-11-20 21:44:56,329 - INFO - Epoch: 02, Compare losses: 19.84576 == 19.84573
2024-11-20 21:44:57,206 - INFO - Epoch: 02, Optimizer LR: 0.30703966, Linear Optimizer LR: 0.00078125
2024-11-20 21:45:01,484 - INFO - Epoch: 02, Test Loss: 1.88225, Test Acc: 30.22%
2024-11-20 21:46:10,504 - INFO - Epoch: 03, biasedVICReg loss: 19.70427, Train Loss: 1.43366, Train Acc: 48.13%
2024-11-20 21:46:10,504 - INFO - Epoch: 03, Invariance loss: 0.03199
2024-11-20 21:46:10,504 - INFO - Epoch: 03, Variance loss: 0.69669
2024-11-20 21:46:10,504 - INFO - Epoch: 03, Covariance loss: 1.48724
2024-11-20 21:46:10,504 - INFO - Epoch: 03, Compare losses: 19.70427 == 19.70427
2024-11-20 21:46:11,349 - INFO - Epoch: 03, Optimizer LR: 0.00160300, Linear Optimizer LR: 0.00078125
2024-11-20 21:46:15,728 - INFO - Epoch: 03, Test Loss: 1.63318, Test Acc: 40.09%
2024-11-20 21:47:19,611 - INFO - Epoch: 04, biasedVICReg loss: 19.59994, Train Loss: 1.36374, Train Acc: 51.05%
2024-11-20 21:47:19,612 - INFO - Epoch: 04, Invariance loss: 0.03004
2024-11-20 21:47:19,612 - INFO - Epoch: 04, Variance loss: 0.69254
2024-11-20 21:47:19,612 - INFO - Epoch: 04, Covariance loss: 1.53525
2024-11-20 21:47:19,612 - INFO - Epoch: 04, Compare losses: 19.59992 == 19.59994
2024-11-20 21:47:20,483 - INFO - Epoch: 04, Optimizer LR: 0.33920262, Linear Optimizer LR: 0.00078125
2024-11-20 21:47:24,937 - INFO - Epoch: 04, Test Loss: 1.66828, Test Acc: 40.66%
2024-11-20 21:48:28,365 - INFO - Epoch: 05, biasedVICReg loss: 19.51771, Train Loss: 1.31518, Train Acc: 53.04%
2024-11-20 21:48:28,365 - INFO - Epoch: 05, Invariance loss: 0.02855
2024-11-20 21:48:28,365 - INFO - Epoch: 05, Variance loss: 0.68905
2024-11-20 21:48:28,366 - INFO - Epoch: 05, Covariance loss: 1.57760
2024-11-20 21:48:28,366 - INFO - Epoch: 05, Compare losses: 19.51770 == 19.51771
2024-11-20 21:48:29,251 - INFO - Epoch: 05, Optimizer LR: 0.15244021, Linear Optimizer LR: 0.00078125
2024-11-20 21:48:33,698 - INFO - Epoch: 05, Test Loss: 1.67258, Test Acc: 41.30%
2024-11-20 21:49:36,894 - INFO - Epoch: 06, biasedVICReg loss: 19.45716, Train Loss: 1.28063, Train Acc: 54.56%
2024-11-20 21:49:36,895 - INFO - Epoch: 06, Invariance loss: 0.02747
2024-11-20 21:49:36,895 - INFO - Epoch: 06, Variance loss: 0.68646
2024-11-20 21:49:36,895 - INFO - Epoch: 06, Covariance loss: 1.60867
2024-11-20 21:49:36,895 - INFO - Epoch: 06, Compare losses: 19.45713 == 19.45716
2024-11-20 21:49:37,731 - INFO - Epoch: 06, Optimizer LR: 0.08712847, Linear Optimizer LR: 0.00078125
2024-11-20 21:49:42,125 - INFO - Epoch: 06, Test Loss: 1.47727, Test Acc: 47.21%
2024-11-20 21:50:44,988 - INFO - Epoch: 07, biasedVICReg loss: 19.40043, Train Loss: 1.24008, Train Acc: 55.86%
2024-11-20 21:50:44,988 - INFO - Epoch: 07, Invariance loss: 0.02640
2024-11-20 21:50:44,988 - INFO - Epoch: 07, Variance loss: 0.68434
2024-11-20 21:50:44,988 - INFO - Epoch: 07, Covariance loss: 1.63201
2024-11-20 21:50:44,988 - INFO - Epoch: 07, Compare losses: 19.40043 == 19.40043
2024-11-20 21:50:45,859 - INFO - Epoch: 07, Optimizer LR: 0.36911131, Linear Optimizer LR: 0.00078125
2024-11-20 21:50:50,291 - INFO - Epoch: 07, Test Loss: 1.40959, Test Acc: 50.92%
2024-11-20 21:51:54,258 - INFO - Epoch: 08, biasedVICReg loss: 19.35511, Train Loss: 1.21100, Train Acc: 57.23%
2024-11-20 21:51:54,258 - INFO - Epoch: 08, Invariance loss: 0.02554
2024-11-20 21:51:54,258 - INFO - Epoch: 08, Variance loss: 0.68232
2024-11-20 21:51:54,258 - INFO - Epoch: 08, Covariance loss: 1.65862
2024-11-20 21:51:54,258 - INFO - Epoch: 08, Compare losses: 19.35511 == 19.35511
2024-11-20 21:51:55,104 - INFO - Epoch: 08, Optimizer LR: 0.02330977, Linear Optimizer LR: 0.00078125
2024-11-20 21:51:59,550 - INFO - Epoch: 08, Test Loss: 1.36131, Test Acc: 52.25%
2024-11-20 21:53:05,179 - INFO - Epoch: 09, biasedVICReg loss: 19.31171, Train Loss: 1.17331, Train Acc: 58.34%
2024-11-20 21:53:05,180 - INFO - Epoch: 09, Invariance loss: 0.02467
2024-11-20 21:53:05,180 - INFO - Epoch: 09, Variance loss: 0.68064
2024-11-20 21:53:05,180 - INFO - Epoch: 09, Covariance loss: 1.67899
2024-11-20 21:53:05,180 - INFO - Epoch: 09, Compare losses: 19.31171 == 19.31171
2024-11-20 21:53:06,030 - INFO - Epoch: 09, Optimizer LR: 0.24548387, Linear Optimizer LR: 0.00078125
2024-11-20 21:53:10,560 - INFO - Epoch: 09, Test Loss: 1.47941, Test Acc: 48.46%
2024-11-20 21:54:13,616 - INFO - Epoch: 10, biasedVICReg loss: 19.27982, Train Loss: 1.14529, Train Acc: 59.47%
2024-11-20 21:54:13,617 - INFO - Epoch: 10, Invariance loss: 0.02410
2024-11-20 21:54:13,617 - INFO - Epoch: 10, Variance loss: 0.67927
2024-11-20 21:54:13,617 - INFO - Epoch: 10, Covariance loss: 1.69541
2024-11-20 21:54:13,617 - INFO - Epoch: 10, Compare losses: 19.27983 == 19.27982
2024-11-20 21:54:14,504 - INFO - Epoch: 10, Optimizer LR: 0.26736951, Linear Optimizer LR: 0.00078125
2024-11-20 21:54:18,856 - INFO - Epoch: 10, Test Loss: 1.28352, Test Acc: 54.49%
2024-11-20 21:55:22,114 - INFO - Epoch: 11, biasedVICReg loss: 19.24491, Train Loss: 1.11530, Train Acc: 60.46%
2024-11-20 21:55:22,114 - INFO - Epoch: 11, Invariance loss: 0.02344
2024-11-20 21:55:22,115 - INFO - Epoch: 11, Variance loss: 0.67775
2024-11-20 21:55:22,115 - INFO - Epoch: 11, Covariance loss: 1.71524
2024-11-20 21:55:22,115 - INFO - Epoch: 11, Compare losses: 19.24490 == 19.24491
2024-11-20 21:55:22,984 - INFO - Epoch: 11, Optimizer LR: 0.01328752, Linear Optimizer LR: 0.00078125
2024-11-20 21:55:27,182 - INFO - Epoch: 11, Test Loss: 1.35092, Test Acc: 53.28%
2024-11-20 21:56:29,259 - INFO - Epoch: 12, biasedVICReg loss: 19.21628, Train Loss: 1.10397, Train Acc: 60.82%
2024-11-20 21:56:29,260 - INFO - Epoch: 12, Invariance loss: 0.02296
2024-11-20 21:56:29,260 - INFO - Epoch: 12, Variance loss: 0.67647
2024-11-20 21:56:29,260 - INFO - Epoch: 12, Covariance loss: 1.73036
2024-11-20 21:56:29,260 - INFO - Epoch: 12, Compare losses: 19.21631 == 19.21628
2024-11-20 21:56:30,106 - INFO - Epoch: 12, Optimizer LR: 0.36183748, Linear Optimizer LR: 0.00078125
2024-11-20 21:56:34,456 - INFO - Epoch: 12, Test Loss: 1.21111, Test Acc: 56.73%
2024-11-20 21:57:39,378 - INFO - Epoch: 13, biasedVICReg loss: 19.19403, Train Loss: 1.07699, Train Acc: 61.76%
2024-11-20 21:57:39,378 - INFO - Epoch: 13, Invariance loss: 0.02243
2024-11-20 21:57:39,378 - INFO - Epoch: 13, Variance loss: 0.67588
2024-11-20 21:57:39,378 - INFO - Epoch: 13, Covariance loss: 1.73645
2024-11-20 21:57:39,378 - INFO - Epoch: 13, Compare losses: 19.19404 == 19.19403
2024-11-20 21:57:40,234 - INFO - Epoch: 13, Optimizer LR: 0.10775549, Linear Optimizer LR: 0.00078125
2024-11-20 21:57:44,548 - INFO - Epoch: 13, Test Loss: 1.14627, Test Acc: 59.51%
2024-11-20 21:58:50,456 - INFO - Epoch: 14, biasedVICReg loss: 19.16382, Train Loss: 1.06025, Train Acc: 62.61%
2024-11-20 21:58:50,456 - INFO - Epoch: 14, Invariance loss: 0.02187
2024-11-20 21:58:50,456 - INFO - Epoch: 14, Variance loss: 0.67450
2024-11-20 21:58:50,456 - INFO - Epoch: 14, Covariance loss: 1.75453
2024-11-20 21:58:50,456 - INFO - Epoch: 14, Compare losses: 19.16381 == 19.16382
2024-11-20 21:58:51,304 - INFO - Epoch: 14, Optimizer LR: 0.12964113, Linear Optimizer LR: 0.00078125
2024-11-20 21:58:55,552 - INFO - Epoch: 14, Test Loss: 1.16635, Test Acc: 58.16%
2024-11-20 21:59:57,171 - INFO - Epoch: 15, biasedVICReg loss: 19.14696, Train Loss: 1.04437, Train Acc: 62.96%
2024-11-20 21:59:57,171 - INFO - Epoch: 15, Invariance loss: 0.02155
2024-11-20 21:59:57,171 - INFO - Epoch: 15, Variance loss: 0.67399
2024-11-20 21:59:57,171 - INFO - Epoch: 15, Covariance loss: 1.75866
2024-11-20 21:59:57,171 - INFO - Epoch: 15, Compare losses: 19.14697 == 19.14696
2024-11-20 21:59:58,103 - INFO - Epoch: 15, Optimizer LR: 0.35181523, Linear Optimizer LR: 0.00078125
2024-11-20 22:00:02,557 - INFO - Epoch: 15, Test Loss: 1.08063, Test Acc: 61.62%
2024-11-20 22:01:04,090 - INFO - Epoch: 16, biasedVICReg loss: 19.12549, Train Loss: 1.03485, Train Acc: 63.25%
2024-11-20 22:01:04,091 - INFO - Epoch: 16, Invariance loss: 0.02111
2024-11-20 22:01:04,091 - INFO - Epoch: 16, Variance loss: 0.67303
2024-11-20 22:01:04,091 - INFO - Epoch: 16, Covariance loss: 1.77208
2024-11-20 22:01:04,091 - INFO - Epoch: 16, Compare losses: 19.12550 == 19.12549
2024-11-20 22:01:04,984 - INFO - Epoch: 16, Optimizer LR: 0.00601369, Linear Optimizer LR: 0.00078125
2024-11-20 22:01:09,598 - INFO - Epoch: 16, Test Loss: 1.15447, Test Acc: 59.04%
2024-11-20 22:02:13,290 - INFO - Epoch: 17, biasedVICReg loss: 19.10889, Train Loss: 1.02802, Train Acc: 63.79%
2024-11-20 22:02:13,291 - INFO - Epoch: 17, Invariance loss: 0.02092
2024-11-20 22:02:13,291 - INFO - Epoch: 17, Variance loss: 0.67218
2024-11-20 22:02:13,291 - INFO - Epoch: 17, Covariance loss: 1.78149
2024-11-20 22:02:13,291 - INFO - Epoch: 17, Compare losses: 19.10887 == 19.10889
2024-11-20 22:02:14,155 - INFO - Epoch: 17, Optimizer LR: 0.28799653, Linear Optimizer LR: 0.00078125
2024-11-20 22:02:18,613 - INFO - Epoch: 17, Test Loss: 1.14150, Test Acc: 59.54%
2024-11-20 22:03:26,494 - INFO - Epoch: 18, biasedVICReg loss: 19.08965, Train Loss: 1.01490, Train Acc: 64.03%
2024-11-20 22:03:26,495 - INFO - Epoch: 18, Invariance loss: 0.02046
2024-11-20 22:03:26,495 - INFO - Epoch: 18, Variance loss: 0.67164
2024-11-20 22:03:26,495 - INFO - Epoch: 18, Covariance loss: 1.78708
2024-11-20 22:03:26,495 - INFO - Epoch: 18, Compare losses: 19.08964 == 19.08965
2024-11-20 22:03:27,377 - INFO - Epoch: 18, Optimizer LR: 0.22268479, Linear Optimizer LR: 0.00078125
2024-11-20 22:03:31,717 - INFO - Epoch: 18, Test Loss: 1.12850, Test Acc: 60.34%
2024-11-20 22:04:34,817 - INFO - Epoch: 19, biasedVICReg loss: 19.07342, Train Loss: 1.00125, Train Acc: 64.41%
2024-11-20 22:04:34,817 - INFO - Epoch: 19, Invariance loss: 0.02015
2024-11-20 22:04:34,817 - INFO - Epoch: 19, Variance loss: 0.67079
2024-11-20 22:04:34,817 - INFO - Epoch: 19, Covariance loss: 1.80001
2024-11-20 22:04:34,817 - INFO - Epoch: 19, Compare losses: 19.07344 == 19.07342
2024-11-20 22:04:35,660 - INFO - Epoch: 19, Optimizer LR: 0.03592238, Linear Optimizer LR: 0.00078125
2024-11-20 22:04:39,995 - INFO - Epoch: 19, Test Loss: 1.15155, Test Acc: 59.42%
2024-11-20 22:05:43,251 - INFO - Epoch: 20, biasedVICReg loss: 19.06387, Train Loss: 0.98672, Train Acc: 65.04%
2024-11-20 22:05:43,251 - INFO - Epoch: 20, Invariance loss: 0.02001
2024-11-20 22:05:43,252 - INFO - Epoch: 20, Variance loss: 0.67044
2024-11-20 22:05:43,252 - INFO - Epoch: 20, Covariance loss: 1.80266
2024-11-20 22:05:43,252 - INFO - Epoch: 20, Compare losses: 19.06386 == 19.06387
2024-11-20 22:05:44,121 - INFO - Epoch: 20, Optimizer LR: 0.37352200, Linear Optimizer LR: 0.00078125
2024-11-20 22:05:48,541 - INFO - Epoch: 20, Test Loss: 1.02945, Test Acc: 63.75%
2024-11-20 22:06:49,935 - INFO - Epoch: 21, biasedVICReg loss: 19.04774, Train Loss: 0.97459, Train Acc: 65.65%
2024-11-20 22:06:49,936 - INFO - Epoch: 21, Invariance loss: 0.01970
2024-11-20 22:06:49,936 - INFO - Epoch: 21, Variance loss: 0.66979
2024-11-20 22:06:49,936 - INFO - Epoch: 21, Covariance loss: 1.81046
2024-11-20 22:06:49,936 - INFO - Epoch: 21, Compare losses: 19.04772 == 19.04774
2024-11-20 22:06:50,782 - INFO - Epoch: 21, Optimizer LR: 0.06808534, Linear Optimizer LR: 0.00078125
2024-11-20 22:06:55,138 - INFO - Epoch: 21, Test Loss: 0.97491, Test Acc: 65.52%
2024-11-20 22:07:56,991 - INFO - Epoch: 22, biasedVICReg loss: 19.03317, Train Loss: 0.96527, Train Acc: 65.66%
2024-11-20 22:07:56,991 - INFO - Epoch: 22, Invariance loss: 0.01942
2024-11-20 22:07:56,991 - INFO - Epoch: 22, Variance loss: 0.66915
2024-11-20 22:07:56,991 - INFO - Epoch: 22, Covariance loss: 1.81887
2024-11-20 22:07:56,991 - INFO - Epoch: 22, Compare losses: 19.03317 == 19.03317
2024-11-20 22:07:57,853 - INFO - Epoch: 22, Optimizer LR: 0.17579320, Linear Optimizer LR: 0.00078125
2024-11-20 22:08:02,221 - INFO - Epoch: 22, Test Loss: 1.10587, Test Acc: 60.72%
2024-11-20 22:09:05,117 - INFO - Epoch: 23, biasedVICReg loss: 19.01455, Train Loss: 0.95580, Train Acc: 66.34%
2024-11-20 22:09:05,118 - INFO - Epoch: 23, Invariance loss: 0.01903
2024-11-20 22:09:05,118 - INFO - Epoch: 23, Variance loss: 0.66834
2024-11-20 22:09:05,118 - INFO - Epoch: 23, Covariance loss: 1.83031
2024-11-20 22:09:05,118 - INFO - Epoch: 23, Compare losses: 19.01455 == 19.01455
2024-11-20 22:09:05,963 - INFO - Epoch: 23, Optimizer LR: 0.32419856, Linear Optimizer LR: 0.00078125
2024-11-20 22:09:10,303 - INFO - Epoch: 23, Test Loss: 0.97066, Test Acc: 65.53%
2024-11-20 22:10:14,529 - INFO - Epoch: 24, biasedVICReg loss: 19.00436, Train Loss: 0.94840, Train Acc: 66.38%
2024-11-20 22:10:14,529 - INFO - Epoch: 24, Invariance loss: 0.01880
2024-11-20 22:10:14,529 - INFO - Epoch: 24, Variance loss: 0.66810
2024-11-20 22:10:14,529 - INFO - Epoch: 24, Covariance loss: 1.83169
2024-11-20 22:10:14,529 - INFO - Epoch: 24, Compare losses: 19.00435 == 19.00436
2024-11-20 22:10:15,403 - INFO - Epoch: 24, Optimizer LR: 0.00012500, Linear Optimizer LR: 0.00078125
2024-11-20 22:10:19,804 - INFO - Epoch: 24, Test Loss: 0.96047, Test Acc: 65.91%
2024-11-20 22:11:26,948 - INFO - Epoch: 25, biasedVICReg loss: 19.00130, Train Loss: 0.94550, Train Acc: 66.60%
2024-11-20 22:11:26,949 - INFO - Epoch: 25, Invariance loss: 0.01886
2024-11-20 22:11:26,949 - INFO - Epoch: 25, Variance loss: 0.66779
2024-11-20 22:11:26,949 - INFO - Epoch: 25, Covariance loss: 1.83485
2024-11-20 22:11:26,949 - INFO - Epoch: 25, Compare losses: 19.00128 == 19.00130
2024-11-20 22:11:27,795 - INFO - Epoch: 25, Optimizer LR: 0.32419856, Linear Optimizer LR: 0.00078125
2024-11-20 22:11:32,155 - INFO - Epoch: 25, Test Loss: 0.97812, Test Acc: 64.65%
2024-11-20 22:12:34,618 - INFO - Epoch: 26, biasedVICReg loss: 18.98375, Train Loss: 0.92671, Train Acc: 67.03%
2024-11-20 22:12:34,618 - INFO - Epoch: 26, Invariance loss: 0.01843
2024-11-20 22:12:34,618 - INFO - Epoch: 26, Variance loss: 0.66710
2024-11-20 22:12:34,619 - INFO - Epoch: 26, Covariance loss: 1.84567
2024-11-20 22:12:34,619 - INFO - Epoch: 26, Compare losses: 18.98375 == 18.98375
2024-11-20 22:12:35,500 - INFO - Epoch: 26, Optimizer LR: 0.17579320, Linear Optimizer LR: 0.00078125
2024-11-20 22:12:39,910 - INFO - Epoch: 26, Test Loss: 0.98409, Test Acc: 64.92%
2024-11-20 22:13:44,397 - INFO - Epoch: 27, biasedVICReg loss: 18.97445, Train Loss: 0.92715, Train Acc: 67.13%
2024-11-20 22:13:44,398 - INFO - Epoch: 27, Invariance loss: 0.01828
2024-11-20 22:13:44,398 - INFO - Epoch: 27, Variance loss: 0.66676
2024-11-20 22:13:44,398 - INFO - Epoch: 27, Covariance loss: 1.84834
2024-11-20 22:13:44,398 - INFO - Epoch: 27, Compare losses: 18.97444 == 18.97445
2024-11-20 22:13:45,276 - INFO - Epoch: 27, Optimizer LR: 0.06808534, Linear Optimizer LR: 0.00078125
2024-11-20 22:13:49,639 - INFO - Epoch: 27, Test Loss: 0.95558, Test Acc: 65.89%
2024-11-20 22:14:51,846 - INFO - Epoch: 28, biasedVICReg loss: 18.96332, Train Loss: 0.91923, Train Acc: 67.63%
2024-11-20 22:14:51,847 - INFO - Epoch: 28, Invariance loss: 0.01805
2024-11-20 22:14:51,847 - INFO - Epoch: 28, Variance loss: 0.66629
2024-11-20 22:14:51,847 - INFO - Epoch: 28, Covariance loss: 1.85486
2024-11-20 22:14:51,847 - INFO - Epoch: 28, Compare losses: 18.96333 == 18.96332
2024-11-20 22:14:52,748 - INFO - Epoch: 28, Optimizer LR: 0.37352200, Linear Optimizer LR: 0.00078125
2024-11-20 22:14:57,110 - INFO - Epoch: 28, Test Loss: 0.90338, Test Acc: 67.60%
2024-11-20 22:16:01,431 - INFO - Epoch: 29, biasedVICReg loss: 18.95925, Train Loss: 0.91077, Train Acc: 67.97%
2024-11-20 22:16:01,431 - INFO - Epoch: 29, Invariance loss: 0.01796
2024-11-20 22:16:01,431 - INFO - Epoch: 29, Variance loss: 0.66627
2024-11-20 22:16:01,431 - INFO - Epoch: 29, Covariance loss: 1.85359
2024-11-20 22:16:01,432 - INFO - Epoch: 29, Compare losses: 18.95926 == 18.95925
2024-11-20 22:16:02,457 - INFO - Epoch: 29, Optimizer LR: 0.03592238, Linear Optimizer LR: 0.00078125
2024-11-20 22:16:06,846 - INFO - Epoch: 29, Test Loss: 0.89407, Test Acc: 67.92%
2024-11-20 22:17:11,930 - INFO - Epoch: 30, biasedVICReg loss: 18.94586, Train Loss: 0.91140, Train Acc: 68.14%
2024-11-20 22:17:11,930 - INFO - Epoch: 30, Invariance loss: 0.01769
2024-11-20 22:17:11,931 - INFO - Epoch: 30, Variance loss: 0.66564
2024-11-20 22:17:11,931 - INFO - Epoch: 30, Covariance loss: 1.86263
2024-11-20 22:17:11,931 - INFO - Epoch: 30, Compare losses: 18.94585 == 18.94586
2024-11-20 22:17:12,790 - INFO - Epoch: 30, Optimizer LR: 0.22268479, Linear Optimizer LR: 0.00078125
2024-11-20 22:17:17,101 - INFO - Epoch: 30, Test Loss: 1.12838, Test Acc: 60.81%
2024-11-20 22:18:21,993 - INFO - Epoch: 31, biasedVICReg loss: 18.93365, Train Loss: 0.90544, Train Acc: 68.03%
2024-11-20 22:18:21,993 - INFO - Epoch: 31, Invariance loss: 0.01742
2024-11-20 22:18:21,994 - INFO - Epoch: 31, Variance loss: 0.66519
2024-11-20 22:18:21,994 - INFO - Epoch: 31, Covariance loss: 1.86836
2024-11-20 22:18:21,994 - INFO - Epoch: 31, Compare losses: 18.93366 == 18.93365
2024-11-20 22:18:22,859 - INFO - Epoch: 31, Optimizer LR: 0.28799653, Linear Optimizer LR: 0.00078125
2024-11-20 22:18:27,296 - INFO - Epoch: 31, Test Loss: 0.90495, Test Acc: 68.02%
2024-11-20 22:19:29,573 - INFO - Epoch: 32, biasedVICReg loss: 18.92603, Train Loss: 0.89374, Train Acc: 68.76%
2024-11-20 22:19:29,573 - INFO - Epoch: 32, Invariance loss: 0.01727
2024-11-20 22:19:29,574 - INFO - Epoch: 32, Variance loss: 0.66491
2024-11-20 22:19:29,574 - INFO - Epoch: 32, Covariance loss: 1.87147
2024-11-20 22:19:29,574 - INFO - Epoch: 32, Compare losses: 18.92603 == 18.92603
2024-11-20 22:19:30,430 - INFO - Epoch: 32, Optimizer LR: 0.00601369, Linear Optimizer LR: 0.00078125
2024-11-20 22:19:34,768 - INFO - Epoch: 32, Test Loss: 0.88552, Test Acc: 68.84%
2024-11-20 22:20:41,112 - INFO - Epoch: 33, biasedVICReg loss: 18.92179, Train Loss: 0.89359, Train Acc: 68.59%
2024-11-20 22:20:41,113 - INFO - Epoch: 33, Invariance loss: 0.01724
2024-11-20 22:20:41,113 - INFO - Epoch: 33, Variance loss: 0.66457
2024-11-20 22:20:41,113 - INFO - Epoch: 33, Covariance loss: 1.87653
2024-11-20 22:20:41,113 - INFO - Epoch: 33, Compare losses: 18.92178 == 18.92179
2024-11-20 22:20:41,965 - INFO - Epoch: 33, Optimizer LR: 0.35181523, Linear Optimizer LR: 0.00078125
2024-11-20 22:20:46,286 - INFO - Epoch: 33, Test Loss: 0.88482, Test Acc: 68.54%
2024-11-20 22:21:51,692 - INFO - Epoch: 34, biasedVICReg loss: 18.91511, Train Loss: 0.88691, Train Acc: 68.85%
2024-11-20 22:21:51,692 - INFO - Epoch: 34, Invariance loss: 0.01715
2024-11-20 22:21:51,692 - INFO - Epoch: 34, Variance loss: 0.66447
2024-11-20 22:21:51,693 - INFO - Epoch: 34, Covariance loss: 1.87470
2024-11-20 22:21:51,693 - INFO - Epoch: 34, Compare losses: 18.91511 == 18.91511
2024-11-20 22:21:52,548 - INFO - Epoch: 34, Optimizer LR: 0.12964113, Linear Optimizer LR: 0.00078125
2024-11-20 22:21:56,996 - INFO - Epoch: 34, Test Loss: 0.88328, Test Acc: 68.39%
2024-11-20 22:23:00,626 - INFO - Epoch: 35, biasedVICReg loss: 18.91021, Train Loss: 0.88483, Train Acc: 68.84%
2024-11-20 22:23:00,627 - INFO - Epoch: 35, Invariance loss: 0.01700
2024-11-20 22:23:00,627 - INFO - Epoch: 35, Variance loss: 0.66423
2024-11-20 22:23:00,627 - INFO - Epoch: 35, Covariance loss: 1.87940
2024-11-20 22:23:00,627 - INFO - Epoch: 35, Compare losses: 18.91018 == 18.91021
2024-11-20 22:23:01,508 - INFO - Epoch: 35, Optimizer LR: 0.10775549, Linear Optimizer LR: 0.00078125
2024-11-20 22:23:05,993 - INFO - Epoch: 35, Test Loss: 0.87595, Test Acc: 69.42%
2024-11-20 22:24:08,111 - INFO - Epoch: 36, biasedVICReg loss: 18.90222, Train Loss: 0.88096, Train Acc: 69.04%
2024-11-20 22:24:08,111 - INFO - Epoch: 36, Invariance loss: 0.01684
2024-11-20 22:24:08,111 - INFO - Epoch: 36, Variance loss: 0.66394
2024-11-20 22:24:08,111 - INFO - Epoch: 36, Covariance loss: 1.88271
2024-11-20 22:24:08,111 - INFO - Epoch: 36, Compare losses: 18.90220 == 18.90222
2024-11-20 22:24:09,007 - INFO - Epoch: 36, Optimizer LR: 0.36183748, Linear Optimizer LR: 0.00078125
2024-11-20 22:24:13,375 - INFO - Epoch: 36, Test Loss: 0.88616, Test Acc: 69.12%
2024-11-20 22:25:17,996 - INFO - Epoch: 37, biasedVICReg loss: 18.89836, Train Loss: 0.87371, Train Acc: 69.25%
2024-11-20 22:25:17,996 - INFO - Epoch: 37, Invariance loss: 0.01680
2024-11-20 22:25:17,996 - INFO - Epoch: 37, Variance loss: 0.66373
2024-11-20 22:25:17,997 - INFO - Epoch: 37, Covariance loss: 1.88501
2024-11-20 22:25:17,997 - INFO - Epoch: 37, Compare losses: 18.89834 == 18.89836
2024-11-20 22:25:18,882 - INFO - Epoch: 37, Optimizer LR: 0.01328752, Linear Optimizer LR: 0.00078125
2024-11-20 22:25:23,294 - INFO - Epoch: 37, Test Loss: 0.85185, Test Acc: 70.19%
2024-11-20 22:26:29,178 - INFO - Epoch: 38, biasedVICReg loss: 18.89338, Train Loss: 0.87477, Train Acc: 69.25%
2024-11-20 22:26:29,178 - INFO - Epoch: 38, Invariance loss: 0.01673
2024-11-20 22:26:29,178 - INFO - Epoch: 38, Variance loss: 0.66348
2024-11-20 22:26:29,178 - INFO - Epoch: 38, Covariance loss: 1.88814
2024-11-20 22:26:29,179 - INFO - Epoch: 38, Compare losses: 18.89340 == 18.89338
2024-11-20 22:26:30,028 - INFO - Epoch: 38, Optimizer LR: 0.26736951, Linear Optimizer LR: 0.00078125
2024-11-20 22:26:34,390 - INFO - Epoch: 38, Test Loss: 0.85398, Test Acc: 69.38%
2024-11-20 22:27:37,667 - INFO - Epoch: 39, biasedVICReg loss: 18.88341, Train Loss: 0.86510, Train Acc: 69.74%
2024-11-20 22:27:37,667 - INFO - Epoch: 39, Invariance loss: 0.01645
2024-11-20 22:27:37,667 - INFO - Epoch: 39, Variance loss: 0.66320
2024-11-20 22:27:37,667 - INFO - Epoch: 39, Covariance loss: 1.89225
2024-11-20 22:27:37,667 - INFO - Epoch: 39, Compare losses: 18.88342 == 18.88341
2024-11-20 22:27:38,523 - INFO - Epoch: 39, Optimizer LR: 0.24548387, Linear Optimizer LR: 0.00078125
2024-11-20 22:27:42,835 - INFO - Epoch: 39, Test Loss: 0.85000, Test Acc: 70.24%
2024-11-20 22:28:44,719 - INFO - Epoch: 40, biasedVICReg loss: 18.88521, Train Loss: 0.86124, Train Acc: 69.68%
2024-11-20 22:28:44,719 - INFO - Epoch: 40, Invariance loss: 0.01653
2024-11-20 22:28:44,719 - INFO - Epoch: 40, Variance loss: 0.66312
2024-11-20 22:28:44,719 - INFO - Epoch: 40, Covariance loss: 1.89406
2024-11-20 22:28:44,719 - INFO - Epoch: 40, Compare losses: 18.88520 == 18.88521
2024-11-20 22:28:45,585 - INFO - Epoch: 40, Optimizer LR: 0.02330977, Linear Optimizer LR: 0.00078125
2024-11-20 22:28:49,941 - INFO - Epoch: 40, Test Loss: 0.90153, Test Acc: 67.76%
2024-11-20 22:29:53,107 - INFO - Epoch: 41, biasedVICReg loss: 18.87176, Train Loss: 0.86104, Train Acc: 69.97%
2024-11-20 22:29:53,108 - INFO - Epoch: 41, Invariance loss: 0.01628
2024-11-20 22:29:53,108 - INFO - Epoch: 41, Variance loss: 0.66268
2024-11-20 22:29:53,108 - INFO - Epoch: 41, Covariance loss: 1.89783
2024-11-20 22:29:53,108 - INFO - Epoch: 41, Compare losses: 18.87176 == 18.87176
2024-11-20 22:29:53,937 - INFO - Epoch: 41, Optimizer LR: 0.36911131, Linear Optimizer LR: 0.00078125
2024-11-20 22:29:58,242 - INFO - Epoch: 41, Test Loss: 0.86202, Test Acc: 69.29%
2024-11-20 22:31:00,382 - INFO - Epoch: 42, biasedVICReg loss: 18.86769, Train Loss: 0.85871, Train Acc: 69.81%
2024-11-20 22:31:00,382 - INFO - Epoch: 42, Invariance loss: 0.01619
2024-11-20 22:31:00,383 - INFO - Epoch: 42, Variance loss: 0.66239
2024-11-20 22:31:00,383 - INFO - Epoch: 42, Covariance loss: 1.90309
2024-11-20 22:31:00,383 - INFO - Epoch: 42, Compare losses: 18.86769 == 18.86769
2024-11-20 22:31:01,208 - INFO - Epoch: 42, Optimizer LR: 0.08712847, Linear Optimizer LR: 0.00078125
2024-11-20 22:31:05,710 - INFO - Epoch: 42, Test Loss: 0.85041, Test Acc: 69.40%
2024-11-20 22:32:09,793 - INFO - Epoch: 43, biasedVICReg loss: 18.86467, Train Loss: 0.85340, Train Acc: 70.00%
2024-11-20 22:32:09,793 - INFO - Epoch: 43, Invariance loss: 0.01614
2024-11-20 22:32:09,793 - INFO - Epoch: 43, Variance loss: 0.66241
2024-11-20 22:32:09,793 - INFO - Epoch: 43, Covariance loss: 1.90092
2024-11-20 22:32:09,793 - INFO - Epoch: 43, Compare losses: 18.86467 == 18.86467
2024-11-20 22:32:10,639 - INFO - Epoch: 43, Optimizer LR: 0.15244021, Linear Optimizer LR: 0.00078125
2024-11-20 22:32:14,955 - INFO - Epoch: 43, Test Loss: 0.90121, Test Acc: 68.38%
2024-11-20 22:33:20,398 - INFO - Epoch: 44, biasedVICReg loss: 18.85779, Train Loss: 0.84937, Train Acc: 70.15%
2024-11-20 22:33:20,398 - INFO - Epoch: 44, Invariance loss: 0.01597
2024-11-20 22:33:20,398 - INFO - Epoch: 44, Variance loss: 0.66211
2024-11-20 22:33:20,398 - INFO - Epoch: 44, Covariance loss: 1.90589
2024-11-20 22:33:20,398 - INFO - Epoch: 44, Compare losses: 18.85779 == 18.85779
2024-11-20 22:33:21,269 - INFO - Epoch: 44, Optimizer LR: 0.33920262, Linear Optimizer LR: 0.00078125
2024-11-20 22:33:25,602 - INFO - Epoch: 44, Test Loss: 0.82575, Test Acc: 70.98%
2024-11-20 22:34:31,196 - INFO - Epoch: 45, biasedVICReg loss: 18.85209, Train Loss: 0.85236, Train Acc: 70.15%
2024-11-20 22:34:31,196 - INFO - Epoch: 45, Invariance loss: 0.01587
2024-11-20 22:34:31,197 - INFO - Epoch: 45, Variance loss: 0.66183
2024-11-20 22:34:31,197 - INFO - Epoch: 45, Covariance loss: 1.90950
2024-11-20 22:34:31,197 - INFO - Epoch: 45, Compare losses: 18.85206 == 18.85209
2024-11-20 22:34:32,074 - INFO - Epoch: 45, Optimizer LR: 0.00160300, Linear Optimizer LR: 0.00078125
2024-11-20 22:34:36,360 - INFO - Epoch: 45, Test Loss: 0.84638, Test Acc: 69.92%
2024-11-20 22:35:39,192 - INFO - Epoch: 46, biasedVICReg loss: 18.84978, Train Loss: 0.84380, Train Acc: 70.19%
2024-11-20 22:35:39,192 - INFO - Epoch: 46, Invariance loss: 0.01581
2024-11-20 22:35:39,192 - INFO - Epoch: 46, Variance loss: 0.66186
2024-11-20 22:35:39,192 - INFO - Epoch: 46, Covariance loss: 1.90794
2024-11-20 22:35:39,192 - INFO - Epoch: 46, Compare losses: 18.84978 == 18.84978
2024-11-20 22:35:39,995 - INFO - Epoch: 46, Optimizer LR: 0.30703966, Linear Optimizer LR: 0.00078125
2024-11-20 22:35:44,579 - INFO - Epoch: 46, Test Loss: 0.81153, Test Acc: 70.89%
2024-11-20 22:36:47,661 - INFO - Epoch: 47, biasedVICReg loss: 18.84131, Train Loss: 0.84297, Train Acc: 70.32%
2024-11-20 22:36:47,661 - INFO - Epoch: 47, Invariance loss: 0.01563
2024-11-20 22:36:47,661 - INFO - Epoch: 47, Variance loss: 0.66151
2024-11-20 22:36:47,662 - INFO - Epoch: 47, Covariance loss: 1.91301
2024-11-20 22:36:47,662 - INFO - Epoch: 47, Compare losses: 18.84131 == 18.84131
2024-11-20 22:36:48,641 - INFO - Epoch: 47, Optimizer LR: 0.19933180, Linear Optimizer LR: 0.00078125
2024-11-20 22:36:53,004 - INFO - Epoch: 47, Test Loss: 0.81552, Test Acc: 71.26%
2024-11-20 22:37:56,539 - INFO - Epoch: 48, biasedVICReg loss: 18.83543, Train Loss: 0.84028, Train Acc: 70.66%
2024-11-20 22:37:56,540 - INFO - Epoch: 48, Invariance loss: 0.01553
2024-11-20 22:37:56,540 - INFO - Epoch: 48, Variance loss: 0.66117
2024-11-20 22:37:56,540 - INFO - Epoch: 48, Covariance loss: 1.91789
2024-11-20 22:37:56,540 - INFO - Epoch: 48, Compare losses: 18.83544 == 18.83543
2024-11-20 22:37:57,478 - INFO - Epoch: 48, Optimizer LR: 0.05092644, Linear Optimizer LR: 0.00078125
2024-11-20 22:38:01,878 - INFO - Epoch: 48, Test Loss: 0.81905, Test Acc: 71.31%
2024-11-20 22:39:09,160 - INFO - Epoch: 49, biasedVICReg loss: 18.83767, Train Loss: 0.83406, Train Acc: 70.85%
2024-11-20 22:39:09,160 - INFO - Epoch: 49, Invariance loss: 0.01554
2024-11-20 22:39:09,161 - INFO - Epoch: 49, Variance loss: 0.66145
2024-11-20 22:39:09,161 - INFO - Epoch: 49, Covariance loss: 1.91287
2024-11-20 22:39:09,161 - INFO - Epoch: 49, Compare losses: 18.83764 == 18.83767
2024-11-20 22:39:10,142 - INFO - Epoch: 49, Optimizer LR: 0.37500000, Linear Optimizer LR: 0.00078125
2024-11-20 22:39:14,505 - INFO - Epoch: 49, Test Loss: 0.83354, Test Acc: 70.16%
